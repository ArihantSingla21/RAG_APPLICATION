{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG APPLICATION PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "# from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "# from llama_index.core.prompts.prompts import SimpleInputPrompt\n",
    "# from transformers import pipeline\n",
    "\n",
    "# # Define the prompt template\n",
    "# documents = SimpleDirectoryReader('DATA').load_data() \n",
    "# query_prompt_template = (\n",
    "#     \"Below is a question:\\n\"\n",
    "#     \"Question: {query_str}\\n\"\n",
    "#     \"Please provide an answer based on the context:\\n\"\n",
    "#     \"Answer: \"\n",
    "# )\n",
    "# query_prompt = SimpleInputPrompt(query_prompt_template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader,ServiceContext \n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core.prompts.prompts import SimpleInputPrompt\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "# Load environment variables\n",
    "# load_dotenv()\n",
    "documents = SimpleDirectoryReader('DATA').load_data() \n",
    "# # Get API key from environment\n",
    "# os.environ[\"HUGGINGFACE_API_KEY\"] = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "# if not hugging_face_key:\n",
    "#     raise ValueError(\"HUGGINGFACE_API_KEY not found in environment variables\")\n",
    "\n",
    "# Define the prompt template\n",
    "query_prompt_template = \"\"\"\n",
    "    \"Below is a question:\\n\"\n",
    "    f\"Question: {query_str}\\n\"\n",
    "    \"Please provide an answer based on the context:\\n\"\n",
    "    \"Answer: \"\n",
    "\"\"\"\n",
    "query_prompt = SimpleInputPrompt(query_prompt_template)\n",
    "\n",
    "# from llama_cpp import Llama\n",
    "\n",
    "# llm = Llama.from_pretrained(\n",
    "# \trepo_id=\"TheBloke/OpenHermes-2.5-Mistral-7B-GGUF\",\n",
    "# \tfilename=\"openhermes-2.5-mistral-7b.Q2_K.gguf\",\n",
    "# )\n",
    "\n",
    "\n",
    "# ## another way to load the model and tokenizer\n",
    "# model_name = \"gpt2\"  # You can change this to your preferred model\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# llm = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='3320f6dc-d5ae-49e1-8f75-5aa784c5d71c', embedding=None, metadata={'page_label': '1', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Citation: Taherdoost, H. Blockchain\\nTechnology and Artiﬁcial Intelligence\\nTogether: A Critical Review on\\nApplications. Appl. Sci. 2022, 12,\\n12948. https://doi.org/10.3390/\\napp122412948\\nAcademic Editor: Christos Bouras\\nReceived: 22 November 2022\\nAccepted: 11 December 2022\\nPublished: 16 December 2022\\nPublisher’s Note:MDPI stays neutral\\nwith regard to jurisdictional claims in\\npublished maps and institutional afﬁl-\\niations.\\nCopyright: © 2022 by the author.\\nLicensee MDPI, Basel, Switzerland.\\nThis article is an open access article\\ndistributed under the terms and\\nconditions of the Creative Commons\\nAttribution (CC BY) license (https://\\ncreativecommons.org/licenses/by/\\n4.0/).\\napplied  \\nsciences \\nReview\\nBlockchain Technology and Artiﬁcial Intelligence Together: A\\nCritical Review on Applications\\nHamed Taherdoost\\nDepartment of Arts, Communications and Social Sciences, University Canada West, Vancouver, BC V6Z 0E5,\\nCanada; hamed.taherdoost@gmail.com; Tel.: +1-236-889-5359\\nAbstract: It is undeniable that the adoption of blockchain- and artiﬁcial intelligence (AI)-based\\nparadigms is proceeding at lightning speed. Both paradigms provide something new to the market,\\nbut the degree of novelty and complexity of each is different. In the age of digital money, blockchains\\nmay automate installments to allow for the safe, decentralized exchange of personal data, information,\\nand logs. AI and blockchains are two of the most talked about technologies right now. Using a\\ndecentralized, secure, and trustworthy system, blockchain technology can automate bitcoin payments\\nand provide users access to a shared ledger of records, transactions, and data. Through the use\\nof smart contracts, a blockchain may also regulate user interactions without the need for a central\\nauthority. As an alternative, AI provides robots with the ability to reason and make decisions and\\nhuman-level intellect. This revelation led to a thorough assessment of the AI and blockchain combo\\ncreated between 2012 and 2022. This critical review contains 121 articles from the recent decade\\nthat investigate the present situation and rationale of the AI and blockchain combination. The\\nintegration’s practical application is the emphasis of this overview’s meatiest portion. In addition,\\nthe gaps and problems of this combination in the linked literature have been studied, with a focus on\\nthe constraints.\\nKeywords: blockchain technology; artiﬁcial intelligence; AI; critical review; AI applications\\n1. Introduction\\nIt is not a secret that there are many new technologies being promoted right now, but\\namong them, the blockchain has been gaining a lot of traction as a decentralized ledger sys-\\ntem that can be used in a variety of settings [1,2]. Since its inception in the 1920s, blockchain\\nhas persisted as a potentially disruptive innovation that will affect the ways of work-\\ning together, automating payments, monitoring markets, and recording transactions [3].\\nBlockchain technology has the potential to be very useful in eliminating the need for a\\ncentral authority ﬁgure to oversee and verify transactions and agreements between many\\nparties [4]. Each transaction in the blockchain is cryptographically hashed and veriﬁed\\nby all mining nodes [5]. It creates immutable, secure, and accessible timestamped records\\nthat can be accessed by all parties involved [ 6]. Artiﬁcial intelligence (AI), which gives\\nmachines the ability to learn from data and make decisions based on what they haveve\\nlearned, is another very visible area that is gaining a lot of traction. Ongoing statistical\\npolling predicts that by 2030, the AI sector will be worth as much as USD 13 trillion [7].\\nWhile numerous competing innovations aim to make information in smart homes\\nimpervious to attacks, this is not yet the case. When it comes to protecting the home\\nnetwork from command and control attacks on encrypted data and providing a secure\\nplatform for all the devices in the network to connect, the development of blockchain\\ntechnology is seen as among the most promising [8]. The consensus reached among the\\nnodes in a blockchain ensures that all transactions are recorded permanently [9]. Control\\nattacks on transmitted or stored information are therefore impossible through a single trad.\\nInstead, the preponderance of hubs must be compromised for the attack to succeed [10].\\nAppl. Sci. 2022, 12, 12948. https://doi.org/10.3390/app122412948 https://www.mdpi.com/journal/applsci', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='4c370e58-a959-4170-9c6c-7f5939ef3761', embedding=None, metadata={'page_label': '2', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 2 of 21\\nRecent years have seen progress toward the concept of decentralized AI. A combina-\\ntion of these two technologies is the basis for decentralized AI (blockchains and AI) [11].\\nIn a distributed and intermediary-free manner, it allows for the execution and storage of\\ntrustworthy, carefully tagged, and shared data on the blockchain [ 12]. The blockchain\\nis now anticipated as a trusted platform to preserve such information, and simulated\\nintelligence is described to work with massive amounts of data [13]. Blockchains may be\\nprogrammed with smart contracts, allowing trusted third parties to monitor data access and\\nsharing between users [14]. After being exposed to an autonomous system, a machine, and\\nseveral scenarios, they may adapt and learn, yielding accurate and reliable decision-making\\noutcomes that are unanimously sanctioned by all blockchain mining nodes [15,16].\\nAs a result, everyone with a vested interest may trust and endorse such decisions. AI\\nprocedures using blockchains may provide decentralized deduction of how to promote\\nsecurity and trust in information sharing and choice outcomes across countless independent\\noperators, which can contribute, arrange, and vote on future choices [17].\\nThe convergence of AI and blockchain technology has produced several practical\\nbeneﬁts [18]. Blockchain technology allows for the safe keeping of patient records in the\\nhealthcare industry. If they are permitted access, medical practitioners may learn valuable\\nlessons from the patterns mined by AI in this data. Remarkably, their combined use has\\nenabled the healthcare sector to deal with the COVID-19 pandemic [ 19]. One forward-\\nthinking example is BurstIQ, a blockchain-based startup that offers data solutions for the\\nhealthcare sector and offers a health wallet using blockchain technology, AI, and big data\\nto handle patient data. Medical providers may access patient health data via the wallet\\nwhenever needed [20]. Increased transaction speeds and mutual trust are two ways in\\nwhich merging these two technologies is revolutionizing the ﬁnancial services sector [21].\\nAs can be seen in Figure 1, there are notable differences between blockchains and AI\\nfrom a technological standpoint, yet these two technologies can be combined to address\\neach other’s weaknesses. Integrating AI with a blockchain has been claimed to have\\nfar-reaching implications in ﬁelds as diverse as 6G networks, smart cities, banking, and\\ndriverless cars [22]. Estimates suggest several potential beneﬁts of combining AI with a\\nblockchain. Without relying on a centralized authority or intermediaries, this enables the\\nsafe and reliable distribution of large data sets for analysis, learning, and decision making\\namong many parties [23]. Several new and useful large-scale applications may potentially\\nemerge as a result [24]. As a consequence of a blockchain’s capacity to ensure the veracity\\nof data, it may be used to store both the inputs and outputs of AI systems [ 25]. This\\narticle discusses the advantages of merging blockchain technology with AI. This overview’s\\nmost substantial portion focuses on the integration’s practical use. The difﬁculties are also\\nhighlighted before the conclusion.\\nThe objective of this study is to examine the state of the AI and blockchain combo\\nliterature in a manner that will help emerging researchers catch up on the evolution of\\nthe ﬁeld and provide advice for improving the quality of future research. The structure\\nof the current study is as follows. The research approach used to ﬁnd, ﬁlter, and choose\\nthe literature is covered in depth in the second part. In the third section, the literature on\\nAI and blockchain integration is covered. The most popular articles are presented, their\\napplicability is discussed, and some of the key problems are highlighted. The last section\\nof the study discusses the conclusion.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='b81a82d4-594f-46b1-86f9-ec3fdafb1392', embedding=None, metadata={'page_label': '3', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 3 of 21\\nAppl. Sci. 2022, 12, x FOR PEER REVIEW 3 of 21  \\n \\nFigure 1. Properties of AI and blockchain. \\nThe objective of this study is to examine the state of the AI and blockchain combo \\nliterature in a manner that will help emerging researchers catch up on the evolution of the \\nfield and provide advice for improving the quality of future research. The structure of the \\ncurrent study is as follows. The research approach used to find, filter, and choose the lit-\\nerature is covered in depth in the second part. In the third section, the literature on AI and \\nblockchain integration is covered. The most popular articles are presented, their applica-\\nbility is discussed, and some of the key problems are highlighted. The last section of the \\nstudy discusses the conclusion. \\n2. Research Methodology \\n2.1. Planning the Review \\nThe goal of this critical study was to evaluate the current state of blockchain technol-\\nogy with AI. With the utmost seriousness, all the recent pertinent literature was carefully \\nreviewed for this inquiry. The review strategy made extensive use of structured research \\nquestions (RQs), the Scopus database, and methods for finding and analyzing infor-\\nmation. A specific subset of the required reporting components for critical reviews was \\nchosen to provide a complete and concise evaluation of the research topics. The RQs’ de-\\ntails are as follows: \\nRQ1: How is the field of research doing now? \\nRQ2: What sectors can benefit from the combination of blockchains and AI? \\nRQ3: What applications do blockchains and AI have together? \\nRQ4: What are the challenges in combining blockchains with AI? \\n  \\nBlockchain\\nAI\\nPowered by a central infrastructureAs judgments are determined by machine learning systems, they cannot be communicated to human users and are hence opaque.ProbabilisticModeling and adjusting throughout timeInfrastructure that is decentralized and distributedCan be described to human users and is transparent since it can be monitored.DeterministicImmutable\\nFigure 1. Properties of AI and blockchain.\\n2. Research Methodology\\n2.1. Planning the Review\\nThe goal of this critical study was to evaluate the current state of blockchain technology\\nwith AI. With the utmost seriousness, all the recent pertinent literature was carefully\\nreviewed for this inquiry. The review strategy made extensive use of structured research\\nquestions (RQs), the Scopus database, and methods for ﬁnding and analyzing information.\\nA speciﬁc subset of the required reporting components for critical reviews was chosen to\\nprovide a complete and concise evaluation of the research topics. The RQs’ details are\\nas follows:\\nRQ1: How is the ﬁeld of research doing now?\\nRQ2: What sectors can beneﬁt from the combination of blockchains and AI?\\nRQ3: What applications do blockchains and AI have together?\\nRQ4: What are the challenges in combining blockchains with AI?\\n2.2. Research Strategy\\nA holistic review of the literature necessitated an inclusive perspective. Throughout\\nthe study, Scopus sources were examined. Relevant databases were thoroughly searched to\\nmake sure the data supplied here were complete. For several reasons, not all outstanding\\npieces of literature were included in the search criteria. A thorough literature search was\\nconducted to reach this objective. Up to now, 353 Scopus results have been analyzed.\\nAbout 121 were considered important (Figure 2). The formulation of the search string was\\ninﬂuenced by the study domain and research subjects. By searching “Artiﬁcial intelligence”\\nOR “AI” AND “blockchain”, relevant content was located and compiled:', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='4764d6d2-a369-40cf-afb2-58e808e6d292', embedding=None, metadata={'page_label': '4', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 4 of 21\\nAppl. Sci. 2022, 12, x FOR PEER REVIEW 4 of 21 \\n \\n2.2. Research Strategy \\nA holistic review of the literature necessitated an inclusive perspective. Throughout \\nthe study, Scopus sources were examined. Relevant databases were thoroughly searched \\nto make sure the data supplied here were complete. For several reasons, not all outstand-\\ning pieces of literature were included in the search criteria. A thorough literature search \\nwas conducted to reach this objective. Up to now, 353 Scopus results have been analyzed. \\nAbout 121 were considered important (Figure 2). The formulation of the search string was \\ninfluenced by the study domain and research  subjects. By searching “Artificial intelli-\\ngence” OR “AI” AND “blockchain”, relevant content was located and compiled: \\n\\uf0a7 Inclusion criteria (ICs). \\n• The publication of research may occur at any time between 2012 and 2022. \\n• The paper must combine blockchain technology and AI. \\n• The scope of the study is limited to the journal. \\n\\uf0a7 Exclusion criteria (EC). \\n• The deletion of articles in the press. \\n• Articles not written in English. \\n• Exclusion of book chapters, dissertations, conference proceedings, interview-\\nbased works, and reviews. \\n \\nFigure 2. Diagram of research method. \\n3. Blockchain and Artificial Intelligence \\nThe results of answering the RQs given in th e preceding critical review follow. This \\nstudy seems to substantially advance the use of the AI and blockchain combination. This \\nsection describes the AI and blockchain comb ination and its foundations, variations, de-\\nvelopment teams, platforms, and consensus procedures. The importance and applications \\nof employing the AI and blockchain combination will be discussed in further detail in the \\nfuture. The responses to the RQs from the crit ical review that came before are included \\nhere. This research seems to significantly enhance the application of blockchain technol-\\nogy and AI together. This section explains the foundations, variants, development teams, \\nplatforms, and consensus mechanisms for the AI and blockchain combo. \\n  \\nInclusion criteria (ICs).\\n• The publication of research may occur at any time between 2012 and 2022.\\n• The paper must combine blockchain technology and AI.\\n• The scope of the study is limited to the journal.\\nAppl. Sci. 2022, 12, x FOR PEER REVIEW 4 of 21 \\n \\n2.2. Research Strategy \\nA holistic review of the literature necessitated an inclusive perspective. Throughout \\nthe study, Scopus sources were examined. Relevant databases were thoroughly searched \\nto make sure the data supplied here were complete. For several reasons, not all outstand-\\ning pieces of literature were included in the search criteria. A thorough literature search \\nwas conducted to reach this objective. Up to now, 353 Scopus results have been analyzed. \\nAbout 121 were considered important (Figure 2). The formulation of the search string was \\ninfluenced by the study domain and research  subjects. By searching “Artificial intelli-\\ngence” OR “AI” AND “blockchain”, relevant content was located and compiled: \\n\\uf0a7 Inclusion criteria (ICs). \\n• The publication of research may occur at any time between 2012 and 2022. \\n• The paper must combine blockchain technology and AI. \\n• The scope of the study is limited to the journal. \\n\\uf0a7 Exclusion criteria (EC). \\n• The deletion of articles in the press. \\n• Articles not written in English. \\n• Exclusion of book chapters, dissertations, conference proceedings, interview-\\nbased works, and reviews. \\n \\nFigure 2. Diagram of research method. \\n3. Blockchain and Artificial Intelligence \\nThe results of answering the RQs given in th e preceding critical review follow. This \\nstudy seems to substantially advance the use of the AI and blockchain combination. This \\nsection describes the AI and blockchain comb ination and its foundations, variations, de-\\nvelopment teams, platforms, and consensus procedures. The importance and applications \\nof employing the AI and blockchain combination will be discussed in further detail in the \\nfuture. The responses to the RQs from the crit ical review that came before are included \\nhere. This research seems to significantly enhance the application of blockchain technol-\\nogy and AI together. This section explains the foundations, variants, development teams, \\nplatforms, and consensus mechanisms for the AI and blockchain combo. \\n  \\nExclusion criteria (EC).\\n• The deletion of articles in the press.\\n• Articles not written in English.\\n• Exclusion of book chapters, dissertations, conference proceedings, interview-\\nbased works, and reviews.\\nAppl. Sci. 2022, 12, x FOR PEER REVIEW 4 of 21  \\n2.2. Research Strategy \\nA holistic review of the literature necessitated an inclusive perspective. Throughout \\nthe study, Scopus sources were examined. Relevant databases were thoroughly searched \\nto make sure the data supplied here were complete. For several reasons, not all outstand-\\ning pieces of literature were included in the search criteria. A thorough literature search \\nwas conducted to reach this objective. Up to now, 353 Scopus results have been analyzed. \\nAbout 121 were considered important (Figure 2). The formulation of the search string was \\ninfluenced by the study domain and research subjects. By searching “Artificial intelli-\\ngence” OR “AI” AND “blockchain”, relevant content was located and compiled: \\n\\uf0a7 Inclusion criteria (ICs). \\n\\uf0b7 The publication of research may occur at any time between 2012 and 2022. \\n\\uf0b7 The paper must combine blockchain technology and AI. \\n\\uf0b7 The scope of the study is limited to the journal. \\n\\uf0a7 Exclusion criteria (EC). \\n\\uf0b7 The deletion of articles in the press. \\n\\uf0b7 Articles not written in English. \\n\\uf0b7 Exclusion of book chapters, dissertations, conference proceedings, interview-\\nbased works, and reviews. \\n \\nFigure 2. Diagram of research method. \\n3. Blockchain and Artificial Intelligence \\nThe results of answering the RQs given in the preceding critical review follow. This \\nstudy seems to substantially advance the use of the AI and blockchain combination. This \\nsection describes the AI and blockchain combination and its foundations, variations, de-\\nvelopment teams, platforms, and consensus procedures. The importance and applications \\nof employing the AI and blockchain combination will be discussed in further detail in the \\nfuture. The responses to the RQs from the critical review that came before are included \\nhere. This research seems to significantly enhance the application of blockchain technol-\\nogy and AI together. This section explains the foundations, variants, development teams, \\nplatforms, and consensus mechanisms for the AI and blockchain combo. \\n  \\nFigure 2. Diagram of research method.\\n3. Blockchain and Artiﬁcial Intelligence\\nThe results of answering the RQs given in the preceding critical review follow. This\\nstudy seems to substantially advance the use of the AI and blockchain combination. This\\nsection describes the AI and blockchain combination and its foundations, variations, de-\\nvelopment teams, platforms, and consensus procedures. The importance and applications\\nof employing the AI and blockchain combination will be discussed in further detail in the\\nfuture. The responses to the RQs from the critical review that came before are included here.\\nThis research seems to signiﬁcantly enhance the application of blockchain technology and\\nAI together. This section explains the foundations, variants, development teams, platforms,\\nand consensus mechanisms for the AI and blockchain combo.\\nSelection Results\\nIn total, 353 items were generated by this search, and 232 of them were inspected.\\nThere are 121 articles in this critical review. The publications that were selected are listed\\nbelow, along with an explanation of the overall classiﬁcation results.\\nRQ1: How is the ﬁeld of research doing now?\\nThis critical study looks at the descriptive data that were gathered on the various\\npapers that are published every year, the publishing source, and the yearly average amount\\nof citations that research publications receive. This critical analysis concludes the study of\\nresearch papers combining AI and blockchains that were released between 2012 and 2022.\\nThe IEEE Access magazine had the most papers on this subject (10 articles).\\nFigure 3 displays the number of articles created for each subject area from 2012 to\\n2022. Computer science (84 articles) and engineering were the primary topics (52 arti-\\ncles). In addition, there were articles on mathematics (15 articles), materials science (12', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='66f9531f-aa73-4800-b12e-423b2a0ddccf', embedding=None, metadata={'page_label': '5', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 5 of 21\\narticles), social sciences (10 articles), decision sciences (9 articles), medicine (9 articles),\\nbusiness, management, and accounting (8 articles), energy (8 articles), health professions\\n(7 articles), economics, econometrics and ﬁnance (4 articles), neuroscience (4 articles), bio-\\nchemistry, genetics, and molecular biology (3 articles), physics and astronomy (3 articles),\\nagricultural and biological sciences (2 articles), environmental science (2 articles), nursing\\n(2 articles), arts and humanities (1 article), chemical engineering (1 article), chemistry (1 ar-\\nticle), dentistry (1 article), and multidisciplinary (1 article). Nearly 35% of the research was\\nin computer science, which is fundamental and the inherent nature of blockchains and AI.\\nThe next category is engineering, which may usefully include all of these topics.\\nAppl. Sci. 2022, 12, x FOR PEER REVIEW 5 of 21  \\nSelection Results \\nIn total, 353 items were generated by this search, and 232 of them were inspected. \\nThere are 121 articles in this critical review. The publications that were selected are listed \\nbelow, along with an explanation of the overall classification results. \\nRQ1: How is the field of research doing now? \\nThis critical study looks at the descriptive data that were gathered on the various \\npapers that are published every year, the publishing source, and the yearly average \\namount of citations that research publications receive. This critical analysis concludes the \\nstudy of research papers combining AI and blockchains that were released between 2012 \\nand 2022. The IEEE Access magazine had the most papers on this subject (10 articles). \\nFigure 3 displays the number of articles created for each subject area from 2012 to \\n2022. Computer science (84 articles) and engineering were the primary topics (52 articles). \\nIn addition, there were articles on mathematics (15 articles), materials science (12 articles), \\nsocial sciences (10 articles), decision sciences (9 articles), medicine (9 articles), business, \\nmanagement, and accounting (8 articles), energy (8 articles), health professions (7 articles), \\neconomics, econometrics and finance (4 articles), neuroscience (4 articles), biochemistry, \\ngenetics, and molecular biology (3 articles), physics and astronomy (3 articles), agricul-\\ntural and biological sciences (2 articles), environmental science (2 articles), nursing (2 ar-\\nticles), arts and humanities (1 article), chemical engineering (1 article), chemistry (1 arti-\\ncle), dentistry (1 article), and multidisciplinary (1 article). Nearly 35% of the research was \\nin computer science, which is fundamental and the inherent nature of blockchains and AI. \\nThe next category is engineering, which may usefully include all of these topics. \\n \\nFigure 3. The number of articles published on the topic between 2012 and 2022. \\nFigure 4 illustrates the number of papers produced in each year from 2012 to 2022. \\nThere was no content available between 2012 and 2017. Here, 2018 witnessed the publica-\\ntion of four publications. In 2019, 2020, and 2021, 13, 21, and 36 papers were published, \\n84521512109 98 874 43 32 2 21 1 1 1 10102030405060708090\\nFigure 3. The number of articles published on the topic between 2012 and 2022.\\nFigure 4 illustrates the number of papers produced in each year from 2012 to 2022.\\nThere was no content available between 2012 and 2017. Here, 2018 witnessed the publication\\nof four publications. In 2019, 2020, and 2021, 13, 21, and 36 papers were published,\\nrespectively. The increasing pace of article publication was followed by 47 articles published\\nin 2022. The concept of merging blockchain and AI technology has been forming and\\nexpanding over the last 5 years.\\nMoreover, the main keywords ( repeated ≥10 times) employed in the articles were\\n“Blockchain”, “Artiﬁcial Intelligence”, “Block-chain”, “ Internet of Things”, “Big Data”,\\n“Deep Learning”, “Deep Learning”, “Deep Learning Security”, “AI”, “Health Care”, “Smart\\nContract”, “Digital Storage”, and “Machine Learning”, as shown in Figure 5. As can be\\nseen, “Blockchain” was the most repeatable keyword, followed by “Artiﬁcial Intelligence”.\\nBlockchain and artiﬁcial intelligence had the greatest repetition. Table 1 presents the top\\nten papers published between 2012 and 2022 in terms of citations.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='ab3e4c7c-25c9-415f-95da-3964201d7552', embedding=None, metadata={'page_label': '6', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 6 of 21\\nAppl. Sci. 2022, 12, x FOR PEER REVIEW 6 of 21  \\nrespectively. The increasing pace of article publication was followed by 47 articles pub-\\nlished in 2022. The concept of merging blockchain and AI technology has been forming \\nand expanding over the last 5 years. \\n \\nFigure 4. The number of annual publications between 2012 and 2022. \\nMoreover, the main keywords ( repeated ≥10 times) employed in the articles were \\n“Blockchain”, “Artificial Intelligence”, “Block-chain”, “ Internet of Things”, “Big Data”, \\n“Deep Learning”, “Deep Learning”, “Deep Learning Security”, “AI”, “Health Care”, \\n“Smart Contract”, “Digital Storage”, and “Machine Learning”, as shown in Figure 5. As \\ncan be seen, “Blockchain” was the most repeatable keyword, followed by “Artificial Intel-\\nligence”. Blockchain and artificial intelligence had the greatest repetition. Table 1 presents \\nthe top ten papers published between 2012 and 2022 in terms of citations. \\n \\nFigure 5. The articles’ primary keywords. \\n0 0 0 0 0 0413213647051015202530354045502012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022QuantityYear\\nBlockchain 30%Artificial Intelligence 21%Block-chain 10%Internet Of Things7%Big Data 5%Deep Learning 5%Network Security 4%Security 4%AI 3%Health Care 3%Smart Contract 3%Digital Storage 2%Machine Learning 3%\\nFigure 4. The number of annual publications between 2012 and 2022.\\nAppl. Sci. 2022, 12, x FOR PEER REVIEW 6 of 21  \\nrespectively. The increasing pace of article publication was followed by 47 articles pub-\\nlished in 2022. The concept of merging blockchain and AI technology has been forming \\nand expanding over the last 5 years. \\n \\nFigure 4. The number of annual publications between 2012 and 2022. \\nMoreover, the main keywords ( repeated ≥10 times) employed in the articles were \\n“Blockchain”, “Artificial Intelligence”, “Block-chain”, “ Internet of Things”, “Big Data”, \\n“Deep Learning”, “Deep Learning”, “Deep Learning Security”, “AI”, “Health Care”, \\n“Smart Contract”, “Digital Storage”, and “Machine Learning”, as shown in Figure 5. As \\ncan be seen, “Blockchain” was the most repeatable keyword, followed by “Artificial Intel-\\nligence”. Blockchain and artificial intelligence had the greatest repetition. Table 1 presents \\nthe top ten papers published between 2012 and 2022 in terms of citations. \\n \\nFigure 5. The articles’ primary keywords. \\n0 0 0 0 0 0413213647051015202530354045502012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022QuantityYear\\nBlockchain 30%Artificial Intelligence 21%Block-chain 10%Internet Of Things7%Big Data 5%Deep Learning 5%Network Security 4%Security 4%AI 3%Health Care 3%Smart Contract 3%Digital Storage 2%Machine Learning 3%\\nFigure 5. The articles’ primary keywords.\\nThe proportion of writers by nationality is shown in Figure 6. It is evident that China\\nhad the most writers. Australia and India came next. The populations of various nations\\nmay be relevant to this situation.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='5dae7047-6d52-45f1-8a89-3465ef268f9d', embedding=None, metadata={'page_label': '7', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 7 of 21\\nTable 1. Top 10 publications between 2012 and 2022 in terms of citations. The high citation rate\\nindicates that the combination of AI and blockchains is signiﬁcant and progressing.\\nObjective Year Cited by Source\\n1 An in-depth analysis of the COVID-19 pandemic and its management impact using\\n5G, blockchain, AI, drones, and IoT (Internet of Things) 2020 540 [26]\\n2 Blockchain for AI: Look at it and come up with a new research problem 2019 349 [27]\\n3 Decentralizing and accelerating biomedical research and healthcare via the\\nconvergence of blockchain and next-generation AI 2018 234 [28]\\n4 BlockIoTIntelligence: Bringing AI to the IoT with blockchain 2020 180 [11]\\n5 AI and blockchain coming together in an IoT network to create a sustainable\\nsmart city 2020 165 [29]\\n6 Knowledge trading in edge-AI powered IoT: a consortium-based incentive and\\neffective approach 2019 104 [30]\\n7 The convergence of blockchain, AI, and 3D printing has the potential to\\nrevolutionize how humanitarian supply chains are run. 2020 80 [31]\\n8 Problems, strategies, and future trends of energy cloud management with\\nblockchain and AI 2020 67 [32]\\n9 Business transformation via digital innovations: use of cloud, data analytics,\\nblockchain, AI, and other technologies 2022 58 [33]\\n10 How might AI powered by many sensors and blockchain change the cyclic\\neconomy of plastic waste from garbage to cash? 2020 42 [34]\\nAppl. Sci. 2022, 12, x FOR PEER REVIEW 7 of 21  \\nThe proportion of writers by nationality is shown in Figure 6. It is evident that China \\nhad the most writers. Australia and India came next. The populations of various nations \\nmay be relevant to this situation. \\n \\nFigure 6. Distribution of authors by country. \\nTable 1. Top 10 publications between 2012 and 2022 in terms of citations. The high citation rate \\nindicates that the combination of AI and blockchains is significant and progressing. \\n Objective Year Cited by  Source \\n1 An in-depth analysis of the COVID-19 pandemic and its management impact using \\n5G, blockchain, AI, drones, and IoT (Internet of Things) 2020 540 [26] \\n2 Blockchain for AI: Look at it and come up with a new research problem 2019 349 [27] \\n3 Decentralizing and accelerating biomedical research and healthcare via the conver-\\ngence of blockchain and next-generation AI  2018 234 [28] \\n4 BlockIoTIntelligence: Bringing AI to the IoT with blockchain  2020 180 [11] \\n5 AI and blockchain coming together in an IoT network to create a sustainable smart \\ncity 2020 165 [29] \\n6 Knowledge trading in edge-AI powered IoT: a consortium-based incentive and effec-\\ntive approach 2019 104 [30] \\n7 The convergence of blockchain, AI, and 3D printing has the potential to revolutionize \\nhow humanitarian supply chains are run. 2020 80 [31] \\n8 Problems, strategies, and future trends of energy cloud management with blockchain \\nand AI 2020 67 [32] \\n9 Business transformation via digital innovations: use of cloud, data analytics, block-\\nchain, AI, and other technologies 2022 58 [33] \\n10 How might AI powered by many sensors and blockchain change the cyclic economy \\nof plastic waste from garbage to cash? 2020 42 [34] \\n3626221312977665555443322222222221111111111111111111111120510152025303540\\nFigure 6. Distribution of authors by country.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='7ff75012-01f3-445e-9b3b-2d0680d4ab8f', embedding=None, metadata={'page_label': '8', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 8 of 21\\n4. Beneﬁts of Blockchains and AI Together\\n4.1. Automation\\nAI, automation, and blockchains may provide value to multi-party business processes\\nby decreasing the need for human intervention, boosting throughput, and facilitating better\\ndata integrity. AI models incorporated in smart contracts implemented on a blockchain\\ncould suggest recalling expired products, reordering, paying, or purchasing stock based\\non predetermined thresholds and events, resolving disputes, and choosing the most en-\\nvironmentally friendly shipping option, among other things. The goal of the research\\narticle by Rajagopal et al. [ 35] was to examine the effects of AI and blockchain technol-\\nogy on an automation service. To obtain pertinent data and information on the study\\nsubject, the researcher chose a secondary data gathering approach. Similar to this, the\\nresources employed quantitative techniques to make the data easier to interpret. Addition-\\nally, this research will aid readers in comprehending the proper efﬁcacy of AI in managing\\nautomation activity.\\n4.2. Augmentation\\nAI can read, analyze, and correlate data with lightning speed and depth, giving\\nblockchain-based business networks a competitive edge. Blockchain enables AI to expand\\nby enabling access to enormous amounts of data from inside and outside the company,\\nallowing for more actionable insights, better management of data consumption and model\\nsharing, and a more transparent and trustworthy data market. By leveraging third parties,\\nor oracles, to process data, Lopes et al. [ 36] suggested an architecture that makes use of\\nblockchain technology as smart contract technology and a ledger for robotic control. They\\ndemonstrated how to securely record events, how smart contracts may be used to drive\\nrobots, and how to interact with outside AI systems for picture analysis. Since the suggested\\narchitecture is simple to integrate, modify, maintain, and expand to other domains, it may\\nbe utilized in a variety of settings including manufacturing, network management, and\\nrobot control.\\n4.3. Authenticity\\nUsing the digital record provided by blockchain technology, the AI’s underlying\\nstructure and the data source it is drawing from can be better understood, thus overcoming\\nthe problem of explainable AI. Trust in data and, by extension, AI-generated suggestions\\nis bolstered as a result. Data security may be improved when a blockchain distributes\\nand stores AI models, particularly when combined with AI. Li et al. [ 37] suggested a\\nblockchain-based data security system for AI in 6G networks. After that, they talked about\\ntwo 6G-related, AI-enabled applications: autonomous vehicles and indoor positioning.\\nThey illustrated the efﬁciency of blockchains in data security via a case study of an indoor\\nnavigation system. Blockchain and AI integration is being developed to assess and improve\\nthe level of intelligent service.\\n5. AI and Blockchain Use Cases\\nIntroducing AI into blockchains creates new possibilities in a wide range of industries.\\n5.1. Supply Chain\\nAI and blockchains are revolutionizing supply chains across sectors by adding automa-\\ntion and intelligence to perform transactions, making the data trustworthy and shareable,\\nand digitizing a formerly paper-based process. Carbon emissions data can be tracked, for\\ninstance, at the product or component level, giving manufacturers more precision and\\ninsight into their decarbonization efforts.\\n5.2. Financial Services\\nThe introduction of trust, the elimination of friction in multi-party transactions, and\\nthe acceleration of transaction speeds are just a few ways AI and blockchains are revolution-', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='7351503f-6445-4d5f-afc9-08b0a1c477d0', embedding=None, metadata={'page_label': '9', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 9 of 21\\nizing the ﬁnancial services business. Take the procedure of obtaining a loan for example.\\nApplicants agree to allow blockchain access to their data. Faster closings and higher\\ncustomer satisfaction may be achieved via a combination of data trust and automated\\napplication evaluation procedures.\\n5.3. Life Sciences\\nThe use of AI and blockchains in the pharmaceutical business has the potential to\\ngreatly increase the success rate of clinical trials while also boosting transparency and\\ntraceability across the medication supply chain. The integrity of data, automation of\\ntrial participation and data collecting, monitoring of patients, management of permission,\\nand openness of data are all made possible by combining powerful data analysis with a\\ndecentralized framework for clinical trials.\\n5.4. Healthcare\\nAI may assist in improving almost every aspect of healthcare, from bringing to light\\ntherapeutic ﬁndings and supporting user demands to recognizing insights from uncovering\\ntrends and patient data. Blockchain technology allows for the safe sharing of sensitive\\npatient information such as electronic health records (EHR) across healthcare providers.\\n5.5. Social Network Analysis\\nOnly a relatively small amount of research considered the inherent social networking\\nproperties of the blockchain [38]. In order to forecast personality, multiple works conducted\\npsychological analyses. Based on the ﬁndings, various researchers developed various\\nmodels that enabled recognizing the characteristics of individuals that characterize their\\npersonalities. These models make it feasible to understand the connections that underlie\\npersonality and psychiatric disorders [39], work performance and satisfaction [ 40], and\\neven interpersonal interactions. Social networks are a good source for personality research\\nof a certain group due to the abundance of information they contain and the millions of\\nmembers they have. The interactions between blockchain users are really quite important\\nfor uncovering previously undiscovered patterns and for opening up fresh perspectives for\\nexamining this speculative bubble. To examine the connections in the blockchain network,\\nsocial network analysis concepts might be of signiﬁcant assistance. In this exercise, it\\nmakes sense to picture a social network where each node represents a user, identiﬁed by\\nblockchain address, and where each arc represents a user-to-user transaction. In order to\\nuncover patterns of user behavior throughout a cryptocurrency speculative bubble and\\ngather information about it, Bonifazi et al. [38] developed a social network analysis-based\\ntechnique. Their method is all-encompassing and can be used to analyze any cryptocur-\\nrency speculative bubble, whether it exists now or in the future. They demonstrated\\nthat their technique includes the capacity to help the search for speculators and that this\\ncapability can include past, current, and future bubbles.\\n6. Why Combine AI with Blockchains\\nThe corporate world and bespoke software development services will see signiﬁcant\\nadoption of these two technologies over the next 5–10 years. Industry executives that\\nare both forward-thinking and tech-savvy still see the immense potential of combining\\nblockchains with AI. Let us take a look at how one may use AI and blockchains for his or\\nher business.\\n6.1. Understanding How AI Thinks\\nHowever advanced AI may be, it will never replace human judgment and hence will\\nnever be widely adopted by the public. The inability to account for the computer’s actions\\nis one of the problems that has slowed the widespread use of AI. The public will quickly\\ncome to trust AI if its decision-making processes can be recorded.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='7516de26-71bf-4eea-b974-b92499f3093b', embedding=None, metadata={'page_label': '10', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 10 of 21\\nIncorporating blockchain technology with AI has the potential to reveal previously\\nhidden processes inside computers. Every AI decision may be recorded and made accessible\\nin a distributed ledger. The information on a blockchain cannot be altered once it has been\\nrecorded, making it ideal for auditing and other security-sensitive applications.\\n6.2. Security Improvement\\nBlockchains include built-in encryption that makes the data very secure. Storing\\nprivate and sensitive information such as medical records or individual recommendations\\non a blockchain makes a lot of sense. Continuous and massive amounts of data are essential\\nfor AI. AI algorithms that can safely process encrypted data are now the focus of intensive\\nresearch and development.\\nIn any case, there is a supplementary viewpoint regarding the enhancement of security.\\nThere is a high level of security in the blockchain itself, but any extra layers or applications\\nare not bulletproof. In the banking sector, machine learning will speed up the rollout of\\nblockchain applications and allow for the prediction of potential system breaches.\\n6.3. Gaining Entry to and Control over the Data Market\\nThis is inextricably linked to better safety measures. With the ability to store massive\\nquantities of encrypted data on a distributed ledger and have AI efﬁciently manage it, fresh\\nuse cases emerge. Blockchain technology makes it possible to keep sensitive information,\\nsuch as medical records, and even beneﬁt from providing others with access to it. That is\\nwhy there are now markets for data, models, and AI.\\nEnhancing the data management processes is another advantage of integrating AI\\nwith a blockchain. To decipher encrypted data, computers go through possible character\\npermutations until they ﬁnd the one that matches the original message. A hacking AI is like\\na person in that it improves with practice. AI, however, will not need a human lifetime to\\nachieve the same level of expertise. This may be accomplished fairly rapidly with sufﬁcient\\ntraining data.\\n6.4. Smart Contract Enhancement\\nCertain vulnerabilities in the blockchain’s underlying technology provide a risk for\\nmalicious actors. This was very recently shown. To put it another way, smart contracts\\nare not that smart yet. Once certain triggers are reached, they will automatically release\\nand transfer the monies. This can only be accomplished after the blockchain community\\nhas reached a uniﬁed decision. Since the code for a smart contract is openly available,\\nanybody may take their time to carefully examine it for vulnerabilities. The use of AI aids\\nin the validation of smart contracts and the forecasting of exploitable ﬂaws. Li et al. [41]\\ncreated Astraea, a private smart contract-based, secure, anonymous, and decentralized\\nauditing platform for contribution systems. In particular, they combined a Distribute\\nSmart Contract (DiSC) with an SGX Enclave to distribute contributions, demonstrate the\\naccuracy of the gift number (intention), and protect the anonymity of donors. They created\\na donation smart contract by using a DiSC to reimburse deposits and protect against theft\\nand collusion attacks from nefarious collectors and transponders. They used security\\nreduction to explicitly describe and demonstrate Astraea’s security and privacy. To carry\\nout an in-depth performance study, they constructed a prototype of Astraea. Astraea is\\nefﬁcient in terms of both computing and communication, according to experimental data.\\n6.5. Maximizing Energy Efﬁciency\\nEnergy consumption is high while data mining. This is a huge problem in the con-\\ntemporary world, but Google has shown that machine learning can solve it. By feeding\\nthe DeepMind AI historical data from hundreds of sensors inside a data center, Google\\nhas enabled cutting down on the amount of energy needed to keep its data center at a\\ncomfortable temperature by 40 percent. Using this similar concept, mining hardware costs\\nmay be reduced.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='b7daf40b-e729-4ccb-8197-ba87aef9d5d1', embedding=None, metadata={'page_label': '11', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 11 of 21\\n7. AI Applications Powered by a Blockchain\\nThis section presents research published in the literature on the application of blockchain\\ntechnology and AI to better manage and protect data and algorithms and answer RQ3: What\\napplications do blockchains and AI have together?\\n7.1. Smart Grid\\nEverybody contributes to the energy supply in a smart grid, which is part of the\\nenergy Internet [42,43]. Smart grids are currently following a trend toward distributed\\nenergy trading, but this model is incompatible with the centralization of traditional grids.\\nTherefore, the smart blockchain’s distributed nature can greatly aid in facilitating the\\nshift from centralized to distributed power in smart grids [ 44]. The smart blockchain’s\\ndecentralized nature allows for the elimination of information silos and the realization of\\ntrustless data exchange between multiple parties [45]. In addition to lowering the price of\\nkeeping smart grids running, blockchain technology can also increase market participation\\nand reduce associated operating expenses [46]. The research by Wang et al. [47] suggests\\nan AEBIS, or AI-enabled electric vehicle integration system, for power management in a\\nplatform for smart grids. An electric vehicle ﬂeet is used as both a consumer and a supplier\\nof electrical energy within a virtual power plant (VPP) platform in the system, which is\\nbuilt on an artiﬁcial neural network and federated learning methodologies. The suggested\\nsystem generates dependable and timely service to deliver additional electricity from the\\nvehicular network, reducing the level of power ﬂuctuation with the correct prediction of\\npower use. Additionally, the use of AI chips provides cost-effective performance. At the\\nexpense of a manageable memory and latency cost, adding a blockchain to the system\\nfurther delivers a safe and transparent service. Figure 7 depicts the graph of incorporating\\nblockchains and AI into smart grids.\\nAppl. Sci. 2022, 12, x FOR PEER REVIEW 11 of 21  \\n6.5. Maximizing Energy Efficiency \\nEnergy consumption is high while data mining. This is a huge problem in the con-\\ntemporary world, but Google has shown that machine learning can solve it. By feeding \\nthe DeepMind AI historical data from hundreds of sensors inside a data center, Google \\nhas enabled cutting down on the amount of energy needed to keep its data center at a \\ncomfortable temperature by 40 percent. Using this similar concept, mining hardware costs \\nmay be reduced. \\n7. AI Applications Powered by a Blockchain \\nThis section presents research published in the literature on the application of block-\\nchain technology and AI to better manage and protect data and algorithms and answer \\nRQ3: What applications do blockchains and AI have together? \\n7.1. Smart Grid \\nEverybody contributes to the energy supply in a smart grid, which is part of the en-\\nergy Internet [42,43]. Smart grids are currently following a trend toward distributed en-\\nergy trading, but this model is incompatible with the centralization of traditional grids. \\nTherefore, the smart blockchain’s distributed nature can greatly aid in facilitating the shift \\nfrom centralized to distributed power in smart grids [44]. The smart blockchain’s decen-\\ntralized nature allows for the elimination of information silos and the realization of trust-\\nless data exchange between multiple parties [45]. In addition to lowering the price of keep-\\ning smart grids running, blockchain technology can also increase market participation and \\nreduce associated operating expenses [46]. The research by Wang et al. [47] suggests an \\nAEBIS, or AI-enabled electric vehicle integration system, for power management in a plat-\\nform for smart grids. An electric vehicle fleet is used as both a consumer and a supplier of \\nelectrical energy within a virtual power plant (VPP) platform in the system, which is built \\non an artificial neural network and federated learning methodologies. The suggested sys-\\ntem generates dependable and timely service to deliver additional electricity from the ve-\\nhicular network, reducing the level of power fluctuation with the correct prediction of \\npower use. Additionally, the use of AI chips provides cost-effective performance. At the \\nexpense of a manageable memory and latency cost, adding a blockchain to the system \\nfurther delivers a safe and transparent service. Figure 7 depicts the graph of incorporating \\nblockchains and AI into smart grids. \\n \\nFigure 7. Blockchain applications in smart grids. \\n7.2. Agriculture Aspects \\nUnderstanding blockchain technology and its implications for agrifood is the pri-\\nmary goal of the PPP project titled “Blockchain for Agrifood”. This project is focusing on \\nthe specific aspects of SCM and the necessity of applying blockchains in agrifood chains \\n[48]. According to Markets and Markets, the global blockchain in the agricultural and food \\nsupply chain market is expected to extend to USD 429.7 million by 2023, expanding at a \\nCAGR of 47.8% (2019). In agriculture, blockchain-based data management can improve \\nthe integration of supply chain resources [49]. Figure 8 summarizes the applications of \\nblockchains in smart agriculture. The traceability of food from the farm to the dinner table \\nFigure 7. Blockchain applications in smart grids.\\n7.2. Agriculture Aspects\\nUnderstanding blockchain technology and its implications for agrifood is the primary\\ngoal of the PPP project titled “Blockchain for Agrifood”. This project is focusing on the\\nspeciﬁc aspects of SCM and the necessity of applying blockchains in agrifood chains [48].\\nAccording to Markets and Markets, the global blockchain in the agricultural and food\\nsupply chain market is expected to extend to USD 429.7 million by 2023, expanding at a\\nCAGR of 47.8% (2019). In agriculture, blockchain-based data management can improve\\nthe integration of supply chain resources [ 49]. Figure 8 summarizes the applications of\\nblockchains in smart agriculture. The traceability of food from the farm to the dinner table\\ncan be conﬁrmed by using the blockchain to develop a digital identity for the actual product\\nor service. Using IoT-based smart devices, an AI engine provides proactive assistance to\\nfarmers on sowing, pest control, harvesting, etc. as well as alerts to the farmers. Future\\nfood safety catastrophes, such as the E. coli outbreak that sickened people in 25 states due to\\ncontaminated lettuce, can be better managed with the use of blockchain technology. Using\\nblockchains, AI, and the IoT might boost productivity, cut expenses, and increase revenue\\nfor businesses. Case studies focusing on Chinese pork and Mexican mangoes show that\\nWalmart and Kroger were among the ﬁrst corporations to hold blockchains and use the\\ntechnology in their supply chains [50].', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='67f3a68e-2519-40f5-8330-b9cbe9509293', embedding=None, metadata={'page_label': '12', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 12 of 21\\nAppl. Sci. 2022, 12, x FOR PEER REVIEW 12 of 21  \\ncan be confirmed by using the blockchain to develop a digital identity for the actual prod-\\nuct or service. Using IoT-based smart devices, an AI engine provides proactive assistance \\nto farmers on sowing, pest control, harvesting, etc. as well as alerts to the farmers. Future \\nfood safety catastrophes, such as the E. coli outbreak that sickened people in 25 states due \\nto contaminated lettuce, can be better managed with the use of blockchain technology. \\nUsing blockchains, AI, and the IoT might boost productivity, cut expenses, and increase \\nrevenue for businesses. Case studies focusing on Chinese pork and Mexican mangoes \\nshow that Walmart and Kroger were among the first corporations to hold blockchains and \\nuse the technology in their supply chains [50]. \\n \\nFigure 8. Blockchain applications in smart agriculture. \\nThe agriculture industry is becoming more intelligent, predictive, trackable, and \\ntransparent as AI and blockchains are increasingly integrated. To guarantee openness in \\ntheir food supply chains, the food and dairy industries have adopted blockchain technol-\\nogy platforms. Table 2 summarizes some of the important findings from the literature. \\nTable 2. Agriculture using blockchains and AI. \\nNumber Objective Reference \\n1 Blockchain-based agriculture 4.0 strategy [51] \\n2 Investigating supply chain management using blockchains, AI, \\nand the IoT [52] \\n3 Using blockchains to focus on Food Industry 4.0 [53] \\n7.3. Supply Chain \\nDue to its decentralization, high dependability, and immutability, the blockchain has \\nbecome a significant technological way to overcome the development restrictions of con-\\nventional supply chains [54]. Information asymmetry between downstream and upstream \\nfirms in the supply chain may be successfully resolved via the use of the blockchain net-\\nwork to publish the data held in the database, therefore facilitating the accurate and \\nspeedy exchange and cooperation of logistical data [55]. \\nApplying AI to the blockchain system has the potential to completely automate the \\nsupply chain, hence redefining its very nature. Integrating with the blockchain allows the \\nAI platform to learn from historical purchase data, point-of-sale sales data, etc., allowing \\nfor the identification of data characteristics and the implementation of predictive analysis \\nFigure 8. Blockchain applications in smart agriculture.\\nThe agriculture industry is becoming more intelligent, predictive, trackable, and\\ntransparent as AI and blockchains are increasingly integrated. To guarantee openness in\\ntheir food supply chains, the food and dairy industries have adopted blockchain technology\\nplatforms. Table 2 summarizes some of the important ﬁndings from the literature.\\nTable 2. Agriculture using blockchains and AI.\\nNumber Objective Reference\\n1 Blockchain-based agriculture 4.0 strategy [51]\\n2 Investigating supply chain management using blockchains, AI,\\nand the IoT [52]\\n3 Using blockchains to focus on Food Industry 4.0 [53]\\n7.3. Supply Chain\\nDue to its decentralization, high dependability, and immutability, the blockchain has\\nbecome a signiﬁcant technological way to overcome the development restrictions of con-\\nventional supply chains [54]. Information asymmetry between downstream and upstream\\nﬁrms in the supply chain may be successfully resolved via the use of the blockchain net-\\nwork to publish the data held in the database, therefore facilitating the accurate and speedy\\nexchange and cooperation of logistical data [55].\\nApplying AI to the blockchain system has the potential to completely automate the\\nsupply chain, hence redeﬁning its very nature. Integrating with the blockchain allows the\\nAI platform to learn from historical purchase data, point-of-sale sales data, etc., allowing for\\nthe identiﬁcation of data characteristics and the implementation of predictive analysis such\\nas demand forecasting, sales model forecasting, route planning, and network management\\n(Figure 9) [56]. The solution D’souza et al. [ 57] suggested in their study for the secure\\ndistribution of pharmaceuticals throughout the whole supply chain leverages a blockchain\\nand AI. Using an event request-response method, each product within the chain may be\\nmoved between chain members who have been veriﬁed. Smart contracts are used to record\\nall transactions between entities onto the blockchain, allowing a product to be tracked back\\nto its original source. The results of the experiments demonstrate that our technique is\\nworkable and somewhat more secure than current solutions.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='7ff11028-79a6-466b-b9fd-9a39cf5999e4', embedding=None, metadata={'page_label': '13', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 13 of 21\\nAppl. Sci. 2022, 12, x FOR PEER REVIEW 13 of 21  \\nsuch as demand forecasting, sales model forecasting, route planning, and network man-\\nagement (Figure 9) [56]. The solution D’souza et al. [57] suggested in their study for the \\nsecure distribution of pharmaceuticals throughout the whole supply chain leverages a \\nblockchain and AI. Using an event request-response method, each product within the \\nchain may be moved between chain members who have been verified. Smart contracts are \\nused to record all transactions between entities onto the blockchain, allowing a product to \\nbe tracked back to its original source. The results of the experiments demonstrate that our \\ntechnique is workable and somewhat more secure than current solutions. \\n \\nFigure 9. The applications of integrating AI and blockchains in supply chain. \\n7.4. Internet of Vehicles \\nThe Internet of Vehicles (IoV) has become more significant in the field of intelligent \\ntransportation as a result of the proliferation of communication technologies [58,59]. Alt-\\nhough vehicle-to-vehicle communication through the IoV has the potential to ameliorate \\ncurrent traffic and road safety issues, there is a risk of a trust crisis and other safety con-\\ncerns arising from the technology’s use [60,61]. The development of Internet of Vehicle \\ntechnology may be hastened with the help of a smart blockchain, which can offer trust \\nassurances, trustworthy data security, and efficient incentive systems (Figure 10). Block-\\nchain technology adds new participants (vehicles, people, and service providers) to the \\nchain. Through its openness, anonymity, and immutability, it facilitates data information \\nexchange, increases the security of stored data, and fosters trust between various compo-\\nnents [62]. \\nIn dispersed vehicle networks, standard AI-based algorithms are also ineffective. The \\nresearch by Chai et al. [63] proposed a hierarchical blockchain architecture and a hierar-\\nchical federated learning algorithm for knowledge sharing, wherein cars learn environ-\\nmental data using machine learning techniques and share the learning information with \\none another. Large-scale automotive networks may use the suggested hierarchical block-\\nchain system. The distributed privacy and pattern requirements of IoVs are met by the \\nhierarchical federated learning method. To encourage sharing behaviors, knowledge shar-\\ning is then represented as a trading market process, and the trading process is framed as \\na multi-player and multi-leader game. The suggested hierarchical method may boost shar-\\ning effectiveness and learning quality, according to simulation findings. Additionally, the \\nblockchain-enabled system has good defenses against certain harmful assaults. \\nFigure 9. The applications of integrating AI and blockchains in supply chain.\\n7.4. Internet of Vehicles\\nThe Internet of Vehicles (IoV) has become more signiﬁcant in the ﬁeld of intelligent\\ntransportation as a result of the proliferation of communication technologies [58,59]. Al-\\nthough vehicle-to-vehicle communication through the IoV has the potential to ameliorate\\ncurrent trafﬁc and road safety issues, there is a risk of a trust crisis and other safety con-\\ncerns arising from the technology’s use [60,61]. The development of Internet of Vehicle\\ntechnology may be hastened with the help of a smart blockchain, which can offer trust as-\\nsurances, trustworthy data security, and efﬁcient incentive systems (Figure 10). Blockchain\\ntechnology adds new participants (vehicles, people, and service providers) to the chain.\\nThrough its openness, anonymity, and immutability, it facilitates data information exchange,\\nincreases the security of stored data, and fosters trust between various components [62].\\nAppl. Sci. 2022, 12, x FOR PEER REVIEW 14 of 21  \\n \\nFigure 10. Effects of smart blockchain on IoV. \\n7.5. Healthcare Aspect \\nThe foundation of conventional EHR systems is a centralized architecture which \\ngives one organization overall responsibility for system oversight, coordination, and man-\\nagement. AI has the computing heft to handle large volumes of patient data and the speed \\nto quickly assess them. Despite AI’s impressive capabilities, which have shown that it can \\nperform many dynamic and cognitive functions quicker than a person, some doctors are \\nstill reluctant to use AI to affect a patient’s health [64,65]. Healthcare applications of block-\\nchains and AI are shown in Figure 11. \\n \\nFigure 11. Healthcare applications of AI and blockchains. \\nRecent research [66,67] also shows that distance has a negative correlation with peo-\\nple using health care. Thus far, blockchains and AI are the two technologies that have \\nshown the most promise for improving healthcare delivery. Interest from the academic \\ncommunity has been shown in the area of using these methods in EHR data processing. \\nOn the other hand, blockchain technology has been expanding its presence in the \\nhealthcare sector. To prevent the malicious modification and exploitation of patient data, \\nit addresses the interoperability problems of existing EHR systems [68]. Live AI solutions \\nfor clinical decision support systems and public health management are used by several \\nEHR-based software platforms, including Epic, to forecast hospital readmissions, patient \\nrisk levels, death, and deterioration. Similarly, patients may now use a blockchain-based \\nRole in healthcare\\nPrivacy\\nProtectionEHR\\nHealth Record by Total\\nCurrent Health RecordsSecurity of AI\\nControl of Security\\nHealthcare\\nFigure 10. Effects of smart blockchain on IoV .', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='6592012b-61a4-4397-9faa-eea2ee7fe9be', embedding=None, metadata={'page_label': '14', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 14 of 21\\nIn dispersed vehicle networks, standard AI-based algorithms are also ineffective. The\\nresearch by Chai et al. [63] proposed a hierarchical blockchain architecture and a hierarchical\\nfederated learning algorithm for knowledge sharing, wherein cars learn environmental data\\nusing machine learning techniques and share the learning information with one another.\\nLarge-scale automotive networks may use the suggested hierarchical blockchain system.\\nThe distributed privacy and pattern requirements of IoVs are met by the hierarchical\\nfederated learning method. To encourage sharing behaviors, knowledge sharing is then\\nrepresented as a trading market process, and the trading process is framed as a multi-\\nplayer and multi-leader game. The suggested hierarchical method may boost sharing\\neffectiveness and learning quality, according to simulation ﬁndings. Additionally, the\\nblockchain-enabled system has good defenses against certain harmful assaults.\\n7.5. Healthcare Aspect\\nThe foundation of conventional EHR systems is a centralized architecture which gives\\none organization overall responsibility for system oversight, coordination, and manage-\\nment. AI has the computing heft to handle large volumes of patient data and the speed\\nto quickly assess them. Despite AI’s impressive capabilities, which have shown that it\\ncan perform many dynamic and cognitive functions quicker than a person, some doctors\\nare still reluctant to use AI to affect a patient’s health [64,65]. Healthcare applications of\\nblockchains and AI are shown in Figure 11.\\nAppl. Sci. 2022, 12, x FOR PEER REVIEW 14 of 21  \\n \\nFigure 10. Effects of smart blockchain on IoV. \\n7.5. Healthcare Aspect \\nThe foundation of conventional EHR systems is a centralized architecture which \\ngives one organization overall responsibility for system oversight, coordination, and man-\\nagement. AI has the computing heft to handle large volumes of patient data and the speed \\nto quickly assess them. Despite AI’s impressive capabilities, which have shown that it can \\nperform many dynamic and cognitive functions quicker than a person, some doctors are \\nstill reluctant to use AI to affect a patient’s health [64,65]. Healthcare applications of block-\\nchains and AI are shown in Figure 11. \\n \\nFigure 11. Healthcare applications of AI and blockchains. \\nRecent research [66,67] also shows that distance has a negative correlation with peo-\\nple using health care. Thus far, blockchains and AI are the two technologies that have \\nshown the most promise for improving healthcare delivery. Interest from the academic \\ncommunity has been shown in the area of using these methods in EHR data processing. \\nOn the other hand, blockchain technology has been expanding its presence in the \\nhealthcare sector. To prevent the malicious modification and exploitation of patient data, \\nit addresses the interoperability problems of existing EHR systems [68]. Live AI solutions \\nfor clinical decision support systems and public health management are used by several \\nEHR-based software platforms, including Epic, to forecast hospital readmissions, patient \\nrisk levels, death, and deterioration. Similarly, patients may now use a blockchain-based \\nRole in healthcare\\nPrivacy\\nProtectionEHR\\nHealth Record by Total\\nCurrent Health RecordsSecurity of AI\\nControl of Security\\nHealthcare\\nFigure 11. Healthcare applications of AI and blockchains.\\nRecent research [66,67] also shows that distance has a negative correlation with people\\nusing health care. Thus far, blockchains and AI are the two technologies that have shown\\nthe most promise for improving healthcare delivery. Interest from the academic community\\nhas been shown in the area of using these methods in EHR data processing. On the other\\nhand, blockchain technology has been expanding its presence in the healthcare sector.\\nTo prevent the malicious modiﬁcation and exploitation of patient data, it addresses the\\ninteroperability problems of existing EHR systems [ 68]. Live AI solutions for clinical\\ndecision support systems and public health management are used by several EHR-based\\nsoftware platforms, including Epic, to forecast hospital readmissions, patient risk levels,\\ndeath, and deterioration. Similarly, patients may now use a blockchain-based system called\\nMedRec. Scholars have used a variety of strategies based on blockchain technology and AI\\ntechnologies to study the aforementioned conclusions. Several features allow the health\\nbusiness to conduct comprehensive assessments of data without sacriﬁcing data security\\nor the ability for specialists to obtain data within a predetermined time frame [9]. Using a\\nfocus on AI and the IoT, which have not been combined before [69], this inquiry analyzes\\nthe impacts, suggests a study topic, and explores the utilization of blockchains in food,\\nagriculture, and health. In addition, modern technologies are better equipped to analyze\\nbig data sets in real time, which paves the way for quicker illness diagnosis and detection\\nas well as automated therapy possibilities and comparisons [70]. In addition to enhancing\\ntrust and communication between healthcare providers and their patients, blockchain', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='71bcdc35-a94d-41b2-82c9-25596810457f', embedding=None, metadata={'page_label': '15', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 15 of 21\\ntechnology also facilitates more transparency in the healthcare industry. Table 3 provides a\\nsummary of the key results from the literature.\\nTable 3. Healthcare using blockchains and AI.\\nNumber Objective Reference\\n1 To solve the difﬁcult challenge of data exchange in healthcare [71]\\n2 Using the IoT and blockchains to provide a novel approach for enhancing biomedical\\nresearch to beneﬁt from patient information [28]\\n3 Integrating blockchains, big data, AI, and the IoT for better health and in other industries [25]\\n4 Security and reliability of blockchain technology for use in healthcare predictive modeling\\nthat protects individual privacy [72]\\n5 Blockchain technology’s potential and possible pitfalls in the healthcare industry [73]\\n6 Blockchain-enabled IoT intelligence architecture (BlockIoTIntelligence) [11]\\n7 Data integration with AI and blockchains [74]\\n8 Using AI and blockchains to focus on PHR [75]\\n8. Challenges\\nThis section points out the problems and challenges in the integration of blockchains\\nand AI and answers RQ4: What are the challenges with combining blockchains with AI?\\n8.1. Privacy and Security\\nAmong the obstacles of blockchain application, privacy, security, and landing protec-\\ntion are major concerns [76]. Due to its role as the backbone of the Internet of Value, the\\nblockchain’s inter-node communications are public and transparent, but they may also\\ninclude sensitive data that users would like to keep secret. Therefore, the key to whether\\nor not blockchain applications can be deployed on a big scale is how to safeguard user\\nprivacy. Typical blockchain privacy protection strategies include information concealment\\nand identity confusion. Using privacy-protecting signature technologies such as ring signa-\\ntures and group signatures to muddle the identities of both participants in a transaction,\\nidentity obfuscation technology makes it hard to match the true user to their blockchain\\ntransaction. The supervisor’s private key allows the supervisor to access user data as\\nrequired, protecting users’ identities.\\nThe user’s transaction privacy is successfully protected by information concealing,\\nwhich employs technologies such as secure multiparty computing and zero-knowledge\\nproof to complete transactions without disclosing any private information and to guarantee\\nthe credibility of the ﬁndings. The increased complexity of the calculations, however,\\nresults in a less effective system, and therefore more work has to be carried out to boost its\\nusefulness in real-world contexts. It is not easy to ﬁgure out how to apply AI algorithms\\nsensibly to boost inefﬁcient performance. Furthermore, the current AI algorithm has to be\\nredesigned to be applied to a distributed context.\\nPrivate AI, which combines AI and encryption methods to solve the data security\\nproblem, was recently developed, but prior research has demonstrated that model inversion\\nattacks may be used to reverse-engineer the model parameters to create pictures [77]. In\\nthis context, Khowaja et al. [78] suggested an industrial IoT environment-speciﬁc federated\\nlearning and encryption-based private (FLEP) AI system that offers two-tier security for\\ndata and model parameters. They provided a hypothetical approach to protect the model\\nparameters together with a three-layer encryption mechanism for data security. The\\nsuggested approach, according to experimental data, produces improved encryption quality\\nat the cost of a somewhat longer execution time. By applying a trust-based protection\\nmechanism, Corradini et al. [77] suggested a two-tier blockchain architecture to improve\\nthe security and independence of smart items in the IoT. Smart items are appropriately', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='50fcbf90-7be3-4510-8469-d8255bf9e8f4', embedding=None, metadata={'page_label': '16', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 16 of 21\\ncategorized into communities in this architecture. The ﬁrst-tier blockchain is local and\\nis only used to record probing transactions carried out to assess the conﬁdence of an\\nitem in another one of a different community or of a same community, which reduces the\\ncomplexity of the solution. These transactions are periodically aggregated after a time\\ninterval, and the resulting values are kept on the secondary blockchain. In particular,\\nthe stored values are each object’s standing within its community and each community’s\\nconﬁdence in the other communities inside the framework.\\nMoreover, the blockchain and federated learning integration method has drawn a lot\\nof interest as a new trustworthy data-sharing pattern with privacy protection. Generally\\nspeaking, this approach bypasses the supervision of the computing process and federated\\nlearning model in favor of using blockchain technology to oversee the original data and\\ncomputation outcomes [14]. In order to create a new data privacy sharing paradigm using\\nblockchains and federated learning, Guo et al. [14] presented the ideas of the sandbox and\\nstate channel. They primarily addressed issues with data privacy sharing in federated\\nlearning and the deterioration of system performance brought on by poor data quality.\\nThe simulation results demonstrate that the suggested strategy outperforms and is more\\neffective than the conventional data exchange method.\\n8.2. Credible Oracles\\nBlockchain players may trigger the execution of a smart contract by triggering an\\nexternal event or calling a third-party function. Event or data retrieval automation is not\\na primary focus of smart contract design. To rephrase, the contracts are unable to obtain\\ninformation from the real world. The contracts need to be “pushed” data and events.\\nTo address these issues, it is recommended to employ trustworthy oracles, which are\\nessentially trusted external parties or nodes, to transmit events and data to smart contracts.\\nWhen it comes to maintaining trust, oracles provide a new layer of complexity and potential\\nsecurity risks, as a previously decentralized system becomes centered on a set of oracles\\nthat must be relied upon. Usually, the agreement is reached by a vote among reliable\\noracles [79].\\n8.3. Concerning the Security of Smart Contracts and the Implications of Their Deterministic Execution\\nThe success of a smart contract relies on its implementation being safe against hacks\\nand errors. Code and data on the network should be protected against intrusion wherever\\npossible. For instance, in 2016, hackers exploited a critical ﬂaw in the coding of the Ethereum\\nplatform used to create the smart contract for the DAO. There was a loss of 3.6 million\\nEthers as a consequence of this. This problem, introduced by smart contract programming\\nand other blockchain-based applications, calls for blockchain engineering [80]. Problems\\nwith security in smart contracts may be traced back to careless coding in the languages\\nused to create them. The relevance of vulnerability testing for smart contracts has grown,\\nand as a result, several tools have been created to evaluate the safety of a contract’s source\\ncode [81,82]. Moreover, as it stands right now, there is no such thing as a probabilistic result\\nfor the execution of a smart contract. When AI and machine learning-based decision-making\\nalgorithms are implemented as smart contracts by the mining nodes, the execution output is\\ntypically not deterministic but rather random, unpredictable, and approximative [83]. This\\nmay be a signiﬁcant difﬁculty for decentralized AI. With data input that might be rapidly\\nchanging as much as that of IoT and sensory readings, this calls for a unique approach to\\ndeal with approximation computation and to design consensus protocols for mining nodes\\nfor agreeing on outputs with a certain degree of conﬁdence, accuracy, or precision.\\n8.4. Scalability\\nThe key to the successful rollout of smart blockchain applications is in solving the scal-\\nability problem [84]. Blockchain decentralized applications need the underlying blockchain\\nplatform to function. If the scalability and performance of the system are inadequate, it\\ncannot be deployed as a large-scale application. The blockchain’s scaling concerns may be', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='66d3a65d-bea8-48e9-8d97-9466e11cac39', embedding=None, metadata={'page_label': '17', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 17 of 21\\nbroken down into three primary categories: consistency problems, network latency, and\\nperformance constraints. Most nodes need to agree on the transaction data to guarantee the\\nblockchain’s security. The blockchain will split if the need for consistency in the distributed\\nnetwork is neglected in favor of faster growth. Due to its decentralized nature, blockchain’s\\nscalability is limited by the time it takes for data to travel between nodes in the network.\\nThis is particularly true for longer delays. The key problem that prevents the widespread\\nuse of blockchain applications is the impact of transaction performance on scalability [85].\\nTo maintain security and ultimate consistency, blockchain transactions cannot be completed\\nin parallel, which makes it impossible to boost transaction throughput.\\n8.5. Off-Chain and On-Chain Storage Data Cooperation\\nBlockchain technologies and conventional information storage methods both have\\nadvantages and disadvantages. Both conventional information systems and blockchains\\nrequire off-chain storage and compute infrastructure to boost performance. To accomplish\\nthis, it is necessary to combine blockchain technology with conventional information\\nsystems, with the most important consideration being to guarantee the accuracy and\\nconsistency of both the data on the chain and the data that are stored in conventional\\ndatabases. More importantly, data are essential to the advancement of AI. There are\\nstill several obstacles to the widespread use of AI, such as issues with data quality, data\\nmonopolization, and data abuse. The introduction of blockchain technology opens up new\\navenues for solving these issues. The marriage of blockchains and AI is only useful in the\\nreal economy if the data on the chain are properly combined with the data off the chain [86].\\nIn order to enable model sharing and ensure a fair model-money exchanging process\\nbetween independent developers and ML-as-a-service (MLaaS) providers, Weng et al. [87]\\ndeveloped a model marketplace dubbed Golden Grain. To encourage the loyal contribu-\\ntions of well-trained models, they implemented the swapping process on the blockchain\\nand subsequently created a blockchain-enabled model benchmarking procedure for openly\\ndeciding the model values in accordance with their real-world performances. Their mar-\\nketplace carefully ofﬂoads the laborious computation and designs a protected off-chain\\non-chain interaction protocol based on a trusted execution environment (TEE), for guar-\\nanteeing both the integrity and authenticity of benchmarking, particularly to reduce the\\nblockchain overhead for model benchmarking. In order to show the realistically inex-\\npensive performance of their architecture, they deployed a prototype of Golden Grain\\non the Ethereum blockchain and carry out comprehensive testing using common bench-\\nmark datasets.\\n9. Conclusions\\nThere is no denying the rapid pace at which blockchain- and AI-based concepts are\\nbeing adopted. However, although both paradigms bring something new to the table,\\nthe level of originality and complexity varies widely. Because of the prevalence of digital\\ncurrency in today’s society, blockchain technology may one day automate payments and\\nfacilitate the secure, distributed transfer of sensitive data, information, and transaction\\nrecords. Both blockchains and AI have been in the spotlight recently. Blockchain tech-\\nnology automates bitcoin payments and gives users access to a shared ledger of records,\\ntransactions, and data using a decentralized, secure, and trustworthy system. A central\\nauthority may not be necessary for blockchain technology’s smart contracts to govern\\nuser interactions. AI, on the other hand, gives machines reasoning and decision-making\\ncapabilities on par with humans. However, combining these two technologies might cause\\na dramatic change in the market. Both technologies are state-of-the-art, but by combining\\nthem, work might be completed more quickly and with less effort. This realization led to\\nthe investigation of a rigorous assessment of blockchain and AI combination publications\\nwritten between 2012 and 2022. This presentation examined the current state of blockchain\\nand AI combinations, their applications, and the possible revolutionary effects of their\\nunique traits. There were 121 distinct publications on this topic that were considered for', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='9e210258-344d-4855-9bb9-de33199d27c3', embedding=None, metadata={'page_label': '18', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 18 of 21\\nthis assessment in total. The belief in the potential of AI and blockchains is gaining more\\nand more acceptance. The beneﬁts of combining AI with blockchain technology are covered\\nin this essay. The bulk of this analysis is devoted to the use cases for integration, including\\nsupply chains, ﬁnancial services, healthcare, life sciences, smart grids, agriculture, and the\\nIoV . Before concluding, issues including privacy and security, credible oracles, the security\\nof smart contracts, and the consequences of their deterministic execution, scalability, and\\ncollaboration between off-chain and on-chain data storage were covered.\\nFunding: This research received no external funding.\\nInstitutional Review Board Statement: Not applicable.\\nInformed Consent Statement: Not applicable.\\nData Availability Statement: Not applicable.\\nConﬂicts of Interest: The authors declare no conﬂict of interest.\\nReferences\\n1. Baynham-Herd, Z. Enlist blockchain to boost conservation. Nature 2017, 548, 523. [CrossRef] [PubMed]\\n2. Maxmen, A. AI researchers embrace Bitcoin technology to share medical data. Nature 2018, 555, 293–295. [CrossRef]\\n3. Nakamoto, S. Bitcoin: A Peer-to-Peer Electronic Cash System; 2009. Available online: https://bitcoin.org/bitcoin.pdf (accessed\\non 1 October 2022).\\n4. Taherdoost, H. An Overview of Trends in Information Systems: Emerging Technologies that Transform the Information Technology\\nIndustry. Cloud Comput. Data Sci. 2022, 4, 1–16. [CrossRef]\\n5. Moosavi, N.; Taherdoost, H. Blockchain and Internet of Things (IoT): A Disruptive Integration. In Proceedings of the 2nd\\nInternational Conference on Emerging Technologies and Intelligent Systems (ICETIS 2022), Virtual Conference, 2–3 September\\n2022; Lecture Notes in Networks and Systems. Springer: Berlin/Heidelberg, Germany, 2022.\\n6. Swan, M. Blockchain: Blueprint for a New Economy; O’Reilly Media, Inc.: Sebastopol, CA, USA, 2015.\\n7. Pandl, K.D.; Thiebes, S.; Schmidt-Kraepelin, M.; Sunyaev, A. On the convergence of artiﬁcial intelligence and distributed ledger\\ntechnology: A scoping review and future research agenda. IEEE Access 2020, 8, 57075–57095. [CrossRef]\\n8. Lin, J.; Shen, Z.; Miao, C. Using blockchain technology to build trust in sharing LoRaWAN IoT. In Proceedings of the 2nd\\nInternational Conference on Crowd Science and Engineering, Beijing, China, 6–9 July 2017; pp. 38–43.\\n9. Dai, Y.; Xu, D.; Maharjan, S.; Chen, Z.; He, Q.; Zhang, Y. Blockchain and deep reinforcement learning empowered intelligent 5G\\nbeyond. IEEE Netw. 2019, 33, 10–17. [CrossRef]\\n10. Salimitari, M.; Chatterjee, M.; Yuksel, M.; Pasiliao, E. Proﬁt maximization for bitcoin pool mining: A prospect theoretic approach.\\nIn Proceedings of the 2017 IEEE 3rd International Conference on Collaboration and Internet Computing (CIC), San Jose, CA,\\nUSA, 15–17 October 2017; pp. 267–274.\\n11. Singh, S.K.; Rathore, S.; Park, J.H. Blockiotintelligence: A blockchain-enabled intelligent IoT architecture with artiﬁcial intelligence.\\nFuture Gener. Comput. Syst. 2020, 110, 721–743. [CrossRef]\\n12. Dinh, T.N.; Thai, M.T. AI and blockchain: A disruptive integration. Computer 2018, 51, 48–53. [CrossRef]\\n13. Taherdoost, H. A Critical Review of Blockchain Acceptance Models—Blockchain Technology Adoption Frameworks and\\nApplications. Computers 2022, 11, 24. [CrossRef]\\n14. Wood, G. Ethereum: A secure decentralised generalised transaction ledger. Ethereum Project Yellow Paper2014, 151, 1–32.\\n15. Kumar, A.; Abhishek, K.; Nerurkar, P .; Ghalib, M.R.; Shankar, A.; Cheng, X. Secure smart contracts for cloud-based manufacturing\\nusing Ethereum blockchain. Trans. Emerg. Telecommun. Technol. 2022, 33, e4129. [CrossRef]\\n16. Li, D.; Deng, L.; Cai, Z.; Souri, A. Blockchain as a service models in the Internet of Things management: Systematic review. Trans.\\nEmerg. Telecommun. Technol. 2022, 33, e4139. [CrossRef]\\n17. Wang, S.; Yuan, Y.; Wang, X.; Li, J.; Qin, R.; Wang, F.-Y. An overview of smart contract: Architecture, applications, and future\\ntrends. In Proceedings of the 2018 IEEE Intelligent Vehicles Symposium (IV), Changshu, China, 26–30 June 2018; pp. 108–113.\\n18. Makarius, E.E.; Mukherjee, D.; Fox, J.D.; Fox, A.K. Rising with the machines: A sociotechnical framework for bringing artiﬁcial\\nintelligence into the organization. J. Bus. Res. 2020, 120, 262–273. [CrossRef]\\n19. Fusco, A.; Dicuonzo, G.; Dell’Atti, V .; Tatullo, M. Blockchain in healthcare: Insights on COVID-19.Int. J. Environ. Res. Public\\nHealth 2020, 17, 7167. [CrossRef] [PubMed]\\n20. Daley, S. Tastier Coffee, Hurricane Prediction and Fighting the Opioid Crisis: 31 Ways Blockchain and AI Make a Powerful\\nPair. Builtin in April, 2020. Available online: https://builtin.com/artiﬁcial-intelligence/blockchain-ai-examples (accessed on 1\\nOctober 2022).\\n21. Soleymani, F.; Paquet, E. Financial portfolio optimization with online deep reinforcement learning and restricted stacked\\nautoencoder—DeepBreath. Expert Syst. Appl. 2020, 156, 113456. [CrossRef]', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='1ab6cf26-10f8-4a46-a332-f6b5bbe7a306', embedding=None, metadata={'page_label': '19', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 19 of 21\\n22. Moosavi, N.; Taherdoost, H. Blockchain-Enabled Network for 6G Wireless Communication Systems. In Proceedings of the\\nInternational Conference on Intelligent Cyber Physical Systems and Internet of Things (ICoICI 2022), Coimbatore, India, 11–12\\nAugust 2022; Engineering Cyber-Physical Systems and Critical Infrastructures. Springer: Berlin/Heidelberg, Germany, 2022.\\n23. Parizi, R.M.; Dehghantanha, A. Smart contract programming languages on blockchains: An empirical evaluation of usability and\\nsecurity. In Proceedings of the International Conference on Blockchain, Halifax, NS, Canada, 30 July–3 August 2018; Springer:\\nBerlin/Heidelberg, Germany, 2018; pp. 75–91.\\n24. Parizi, R.M.; Dehghantanha, A.; Choo, K.-K.R.; Singh, A. Empirical vulnerability analysis of automated smart contracts security\\ntesting on blockchains. arXiv 2018, arXiv:1809.02702.\\n25. Rabah, K. Convergence of AI, IoT, big data and blockchain: A review. Lake Inst. J. 2018, 1, 1–18.\\n26. Chamola, V .; Hassija, V .; Gupta, V .; Guizani, M. A comprehensive review of the COVID-19 pandemic and the role of IoT, drones,\\nAI, blockchain, and 5G in managing its impact. IEEE Access 2020, 8, 90225–90265. [CrossRef]\\n27. Salah, K.; Rehman, M.H.U.; Nizamuddin, N.; Al-Fuqaha, A. Blockchain for AI: Review and open research challenges. IEEE Access\\n2019, 7, 10127–10149. [CrossRef]\\n28. Mamoshina, P .; Ojomoko, L.; Yanovich, Y.; Ostrovski, A.; Botezatu, A.; Prikhodko, P .; Izumchenko, E.; Aliper, A.; Romantsov,\\nK.; Zhebrak, A. Converging blockchain and next-generation artiﬁcial intelligence technologies to decentralize and accelerate\\nbiomedical research and healthcare. Oncotarget 2018, 9, 5665. [CrossRef]\\n29. Singh, S.; Sharma, P .K.; Yoon, B.; Shojafar, M.; Cho, G.H.; Ra, I.-H. Convergence of blockchain and artiﬁcial intelligence in IoT\\nnetwork for the sustainable smart city. Sustain. Cities Soc. 2020, 63, 102364. [CrossRef]\\n30. Lin, X.; Li, J.; Wu, J.; Liang, H.; Yang, W. Making knowledge tradable in edge-AI enabled IoT: A consortium blockchain-based\\nefﬁcient and incentive approach. IEEE Trans. Ind. Inform. 2019, 15, 6367–6378. [CrossRef]\\n31. Rodríguez-Espíndola, O.; Chowdhury, S.; Beltagui, A.; Albores, P . The potential of emergent disruptive technologies for\\nhumanitarian supply chains: The integration of blockchain, Artiﬁcial Intelligence and 3D printing. Int. J. Prod. Res. 2020, 58,\\n4610–4630. [CrossRef]\\n32. Kumari, A.; Gupta, R.; Tanwar, S.; Kumar, N. Blockchain and AI amalgamation for energy cloud management: Challenges,\\nsolutions, and future directions. J. Parallel Distrib. Comput. 2020, 143, 148–166. [CrossRef]\\n33. Akter, S.; Michael, K.; Uddin, M.R.; McCarthy, G.; Rahman, M. Transforming business using digital innovations: The application\\nof AI, blockchain, cloud and data analytics. Ann. Oper. Res. 2020, 308, 7–39. [CrossRef]\\n34. Chidepatil, A.; Bindra, P .; Kulkarni, D.; Qazi, M.; Kshirsagar, M.; Sankaran, K. From trash to cash: How blockchain and\\nmulti-sensor-driven artiﬁcial intelligence can transform circular economy of plastic waste? Adm. Sci. 2020, 10, 23. [CrossRef]\\n35. Rajagopal, B.R.; Anjanadevi, B.; Tahreem, M.; Kumar, S.; Debnath, M.; Tongkachok, K. Comparative Analysis of Blockchain\\nTechnology and Artiﬁcial Intelligence and Its Impact on Open Issues of Automation in Workplace. In Proceedings of the 2022 2nd\\nInternational Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE), Greater Noida, India,\\n28–29 April 2022; pp. 288–292.\\n36. Lopes, V .; Alexandre, L.A.; Pereira, N. Controlling robots using artiﬁcial intelligence and a consortium blockchain.arXiv 2019,\\narXiv:1903.00660.\\n37. Li, W.; Su, Z.; Li, R.; Zhang, K.; Wang, Y. Blockchain-based data security for artiﬁcial intelligence applications in 6G networks.\\nIEEE Netw. 2020, 34, 31–37. [CrossRef]\\n38. Bonifazi, G.; Corradini, E.; Ursino, D.; Virgili, L. A social network analysis–based approach to investigate user behaviour during a\\ncryptocurrency speculative bubble. J. Inf. Sci. 2021. [CrossRef]\\n39. Indu, V .; Thampi, S.M. A systematic review on the inﬂuence of User personality in rumor and misinformation propagation\\nthrough social networks. In Proceedings of the International Symposium on Signal Processing and Intelligent Recognition\\nSystems, Online, 29–30 December 2021; Springer: Berlin/Heidelberg, Germany, 2021; pp. 216–242.\\n40. Golbeck, J.; Robles, C.; Turner, K. Predicting personality with social media. In CHI’11 Extended Abstracts on Human Factors in\\nComputing Systems; Association for Computing Machinery: New York, NY, USA, 2011; pp. 253–262.\\n41. Meng, W.; Li, W.; Zhu, L. Enhancing medical smartphone networks via blockchain-based trust management against insider\\nattacks. IEEE Trans. Eng. Manag. 2019, 67, 1377–1386. [CrossRef]\\n42. He, S.; Zhang, Y.; Zhu, R.; Tian, W. Electric signature detection and analysis for power equipment failure monitoring in smart\\ngrid. IEEE Trans. Ind. Inform. 2020, 17, 3739–3750. [CrossRef]\\n43. He, S.; Tian, W.; Zhang, J.; Li, K.; Zhang, M.; Zhu, R. A high efﬁcient approach for power disturbance waveform compression in\\nthe view of heisenberg uncertainty. IEEE Trans. Ind. Inform. 2018, 15, 2580–2591. [CrossRef]\\n44. Mollah, M.B.; Zhao, J.; Niyato, D.; Lam, K.-Y.; Zhang, X.; Ghias, A.M.; Koh, L.H.; Yang, L. Blockchain for future smart grid: A\\ncomprehensive survey. IEEE Internet Things J. 2020, 8, 18–43. [CrossRef]\\n45. Cadoret, D.; Kailas, T.; Velmovitsky, P .; Morita, P .; Igboeli, O. Proposed implementation of blockchain in british columbia’s health\\ncare data management. J. Med. Internet Res. 2020, 22, e20897. [CrossRef] [PubMed]\\n46. Aderibole, A.; Aljarwan, A.; Rehman, M.H.U.; Zeineldin, H.H.; Mezher, T.; Salah, K.; Damiani, E.; Svetinovic, D. Blockchain\\ntechnology for smart grids: Decentralized NIST conceptual model. IEEE Access 2020, 8, 43177–43190. [CrossRef]\\n47. Wang, Z.; Ogbodo, M.; Huang, H.; Qiu, C.; Hisada, M.; Abdallah, A.B. AEBIS: AI-enabled blockchain-based electric vehicle\\nintegration system for power management in smart grid platform. IEEE Access 2020, 8, 226409–226421. [CrossRef]', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='b9e35d97-60a7-479a-9c51-3aec4493d803', embedding=None, metadata={'page_label': '20', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 20 of 21\\n48. Ge, L.; Brewster, C.; Spek, J.; Smeenk, A.; Top, J.; van Diepen, F.; Klaase, B.; Graumans, C.; de Wildt, M.D.R. Blockchain for\\nAgriculture and Food: Findings from the Pilot Study; Wageningen Economic Research: Wageningen, The Netherlands, 2017.\\n49. Kamble, S.S.; Gunasekaran, A.; Gawankar, S.A. Achieving sustainable performance in a data-driven agriculture supply chain: A\\nreview for research and applications. Int. J. Prod. Econ. 2020, 219, 179–194. [CrossRef]\\n50. Insights, C. How Blockchain Could Transform Food Safety; 2017. Available online: https://www.cbinsights.com/research/\\nblockchain-grocery-supply-chain/ (accessed on 1 November 2022).\\n51. De Clercq, M.; Vats, A.; Biel, A. Agriculture 4.0: The future of farming technology. In Proceedings of the World Government\\nSummit, Dubai, United Arab Emirates, 11–13 February 2018; pp. 11–13.\\n52. Lezoche, M.; Hernandez, J.E.; D íaz, M.D.M.E.A.; Panetto, H.; Kacprzyk, J. Agri-food 4.0: A survey of the supply chains and\\ntechnologies for the future agriculture. Comput. Ind. 2020, 117, 103187. [CrossRef]\\n53. Khan, P .W.; Byun, Y.-C.; Park, N. IoT-blockchain enabled optimized provenance system for food industry 4.0 using advanced\\ndeep learning. Sensors 2020, 20, 2990. [CrossRef] [PubMed]\\n54. Wu, H.; Cao, J.; Yang, Y.; Tung, C.L.; Jiang, S.; Tang, B.; Liu, Y.; Wang, X.; Deng, Y. Data management in supply chain using\\nblockchain: Challenges and a case study. In Proceedings of the 2019 28th International Conference on Computer Communication\\nand Networks (ICCCN), Valencia, Spain, 29 July–1 August 2019; pp. 1–8.\\n55. Liu, L.; Zhang, J.Z.; He, W.; Li, W. Mitigating information asymmetry in inventory pledge ﬁnancing through the Internet of things\\nand blockchain. J. Enterp. Inf. Manag. 2021, 34, 1429–1451. [CrossRef]\\n56. Gohil, D.; Thakker, S.V . Blockchain-integrated technologies for solving supply chain challenges.Modern Supply Chain Res. Appl.\\n2021, 3, 78–97. [CrossRef]\\n57. D’souza, S.; Nazareth, D.; Vaz, C.; Shetty, M. Blockchain and AI in Pharmaceutical Supply Chain. In Proceedings of the\\nInternational Conference on Smart Data Intelligence (ICSMDI 2021), Tamil Nadu, India, 29–30 April 2021.\\n58. Du, J.; Yu, F.R.; Chu, X.; Feng, J.; Lu, G. Computation ofﬂoading and resource allocation in vehicular networks based on dual-side\\ncost minimization. IEEE Trans. Veh. Technol.2018, 68, 1079–1092. [CrossRef]\\n59. Dua, A.; Kumar, N.; Das, A.K.; Susilo, W. Secure message communication protocol among vehicles in smart city.IEEE Trans. Veh.\\nTechnol. 2017, 67, 4359–4373. [CrossRef]\\n60. Liu, L.; Chen, C.; Pei, Q.; Maharjan, S.; Zhang, Y. Vehicular edge computing and networking: A survey.Mobile Netw. Appl. 2021,\\n26, 1145–1168. [CrossRef]\\n61. Mollah, M.B.; Azad, M.A.K.; Vasilakos, A. Secure data sharing and searching at the edge of cloud-assisted internet of things.IEEE\\nCloud Comput. 2017, 4, 34–42. [CrossRef]\\n62. Nguyen, D.C.; Pathirana, P .N.; Ding, M.; Seneviratne, A. Blockchain for 5G and beyond networks: A state of the art survey.J.\\nNetw. Comput. Appl. 2020, 166, 102693. [CrossRef]\\n63. Chai, H.; Leng, S.; Chen, Y.; Zhang, K. A hierarchical blockchain-enabled federated learning algorithm for knowledge sharing in\\ninternet of vehicles. IEEE Trans. Intell. Transp. Syst. 2020, 22, 3975–3986. [CrossRef]\\n64. Ghosh, A.; Mistri, B. Spatial disparities in the provision of rural health facilities: Application of GIS based modelling in rural\\nBirbhum, India. Spat. Inf. Res. 2020, 28, 655–668. [CrossRef]\\n65. Bell, L.; Buchanan, W.J.; Cameron, J.; Lo, O. Applications of blockchain within healthcare. Blockchain Healthc. Today 2018, 1, 1–7.\\n[CrossRef]\\n66. Lin, W.-C.; Chen, J.S.; Chiang, M.F.; Hribar, M.R. Applications of artiﬁcial intelligence to electronic health record data in\\nophthalmology. Transl. Vis. Sci. Technol. 2020, 9, 13. [CrossRef]\\n67. Roehrs, A.; Da Costa, C.A.; da Rosa Righi, R.; De Oliveira, K.S.F. Personal health records: A systematic literature review.J. Med.\\nInternet Res. 2017, 19, e5876. [CrossRef]\\n68. Ellingsen, G.; Hertzum, M. User requirements meet large-scale EHR suites: Norwegian preparations for Epic. Stud. Health Technol.\\nInform. 2020, 270, 703–707. [PubMed]\\n69. Al-Shawwa, B.; Glynn, E.; Hoffman, M.A.; Ehsan, Z.; Ingram, D.G. Outpatient health care utilization for sleep disorders in the\\nCerner Health Facts database. J. Clin. Sleep Med. 2021, 17, 203–209. [CrossRef] [PubMed]\\n70. Dlamini, Z.; Francies, F.Z.; Hull, R.; Marima, R. Artiﬁcial intelligence (AI) and big data in cancer and precision oncology. Comput.\\nStruct. Biotechnol. J. 2020, 18, 2300–2311. [CrossRef] [PubMed]\\n71. Peterson, K.; Deeduvanu, R.; Kanjamala, P .; Boles, K. A Blockchain-Based Approach to Health Information Exchange Networks.\\n2016. Available online: https://www.healthit.gov/sites/default/ﬁles/12-55-blockchain-based-approach-ﬁnal.pdf (accessed on 5\\nSeptember 2019).\\n72. Kuo, T.-T.; Ohno-Machado, L. Modelchain: Decentralized privacy-preserving healthcare predictive modeling framework on\\nprivate blockchain networks. arXiv 2018, arXiv:1802.01746.\\n73. Siyal, A.A.; Junejo, A.Z.; Zawish, M.; Ahmed, K.; Khalil, A.; Soursou, G. Applications of blockchain technology in medicine and\\nhealthcare: Challenges and future perspectives. Cryptography 2019, 3, 3. [CrossRef]\\n74. Sgantzos, K.; Grigg, I. Artiﬁcial intelligence implementations on the blockchain. Use cases and future applications. Future Internet\\n2019, 11, 170. [CrossRef]\\n75. Kim, S.-K.; Huh, J.-H. Artiﬁcial neural network blockchain techniques for healthcare system: Focusing on the personal health\\nrecords. Electronics 2020, 9, 763. [CrossRef]', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='b44c11e7-db40-4478-b1ea-1fae4e8bb14b', embedding=None, metadata={'page_label': '21', 'file_name': 'Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/Blockchain_Technology_and_Artificial_Intelligence_.pdf', 'file_type': 'application/pdf', 'file_size': 7277598, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appl. Sci. 2022, 12, 12948 21 of 21\\n76. Syed, F.; Gupta, S.K.; Hamood Alsamhi, S.; Rashid, M.; Liu, X. A survey on recent optimal techniques for securing unmanned\\naerial vehicles applications. Trans. Emerg. Telecommun. Technol. 2021, 32, e4133.\\n77. Corradini, E.; Nicolazzo, S.; Nocera, A.; Ursino, D.; Virgili, L. A two-tier Blockchain framework to increase protection and\\nautonomy of smart objects in the IoT. Comput. Commun. 2022, 181, 338–356. [CrossRef]\\n78. Khowaja, S.A.; Dev, K.; Qureshi, N.M.F.; Khuwaja, P .; Foschini, L. Toward industrial private AI: A two-tier framework for data\\nand model security. IEEE Wirel. Commun. 2022, 29, 76–83. [CrossRef]\\n79. Stradling, A.; Voorhees, E. System and Method of Providing a Multi-Validator Oracle. Google Patents US2,018,009,131,6A1, 2018.\\n80. Destefanis, G.; Marchesi, M.; Ortu, M.; Tonelli, R.; Bracciali, A.; Hierons, R. Smart contracts vulnerabilities: A call for blockchain\\nsoftware engineering? In Proceedings of the 2018 International Workshop on Blockchain Oriented Software Engineering\\n(IWBOSE), Campobasso, Italy, 20–28 March 2018; pp. 19–25.\\n81. Luu, L.; Chu, D.-H.; Olickel, H.; Saxena, P .; Hobor, A. Making smart contracts smarter. In Proceedings of the 2016 ACM SIGSAC\\nConference on Computer and Communications Security, Vienna, Austria, 24–28 October 2016; pp. 254–269.\\n82. Tikhomirov, S.; Voskresenskaya, E.; Ivanitskiy, I.; Takhaviev, R.; Marchenko, E.; Alexandrov, Y. Smartcheck: Static analysis of\\nethereum smart contracts. In Proceedings of the 1st International Workshop on Emerging Trends in Software Engineering for\\nBlockchain, Gothenburg, Sweden, 27 May–3 June 2018; pp. 9–16.\\n83. Kumar, A. A Broad Survey on AI Integration in Blockchain: A Forward-Looking Approach. In Proceedings of the National\\nConference on Recent Trends of Engineering & Technologies, (RTET-2022) Ramgovind Group of Colleges, Koderma, Jharkhand,\\nIndia, 5–7 October 2022; pp. 1–38.\\n84. Worley, C.; Skjellum, A. Blockchain tradeoffs and challenges for current and emerging applications: Generalization, fragmentation,\\nsidechains, and scalability. In Proceedings of the 2018 IEEE International Conference on Internet of Things (iThings) and IEEE\\nGreen Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart\\nData (SmartData), Halifax, NS, Canada, 30 July 2018–3 August 2018; pp. 1582–1587.\\n85. Nasir, M.H.; Arshad, J.; Khan, M.M.; Fatima, M.; Salah, K.; Jayaraman, R. Scalable blockchains—A systematic review. Future\\nGener. Comput. Syst. 2022, 126, 136–162. [CrossRef]\\n86. Kumar, H.; Borah, U. Recent Developments in Joint Artiﬁcial Technology and Blockchain Technology: Its Potential Use for the\\nFuture. Supremo Amic. 2021, 26, 130.\\n87. Weng, J.; Weng, J.; Cai, C.; Huang, H.; Wang, C. Golden grain: Building a secure and decentralized model marketplace for MLaaS.\\nIEEE Trans. Depend. Secure Comput. 2021, 19, 3149–3167. [CrossRef]', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='fb6a4c9d-8995-4a5c-8eb4-71825472d020', embedding=None, metadata={'page_label': '1', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via\\nReinforcement Learning\\nDeepSeek-AI\\nresearch@deepseek.com\\nAbstract\\nWe introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.\\nDeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without super-\\nvised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities.\\nThrough RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing\\nreasoning behaviors. However, it encounters challenges such as poor readability, and language\\nmixing. To address these issues and further enhance reasoning performance, we introduce\\nDeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-\\nR1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the\\nresearch community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models\\n(1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.\\nAIME 2024\\n(Pass@1)\\nCodeforces\\n(Percentile)\\nGPQA Diamond\\n(Pass@1)\\nMATH-500\\n(Pass@1)\\nMMLU\\n(Pass@1)\\nSWE-bench Verified\\n(Resolved)\\n0\\n20\\n40\\n60\\n80\\n100Accuracy / Percentile (%)\\n79.8\\n96.3\\n71.5\\n97.3\\n90.8\\n49.2\\n79.2\\n96.6\\n75.7\\n96.4\\n91.8\\n48.9\\n72.6\\n90.6\\n62.1\\n94.3\\n87.4\\n36.8\\n63.6\\n93.4\\n60.0\\n90.0\\n85.2\\n41.6\\n39.2\\n58.7 59.1\\n90.2\\n88.5\\n42.0\\nDeepSeek-R1 OpenAI-o1-1217 DeepSeek-R1-32B OpenAI-o1-mini DeepSeek-V3\\nFigure 1 |Benchmark performance of DeepSeek-R1.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='14873fb2-2b4c-4783-8f2f-b0e44432ce7a', embedding=None, metadata={'page_label': '2', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Contents\\n1 Introduction 3\\n1.1 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n1.2 Summary of Evaluation Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\n2 Approach 5\\n2.1 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 DeepSeek-R1-Zero: Reinforcement Learning on the Base Model . . . . . . . . . . 5\\n2.2.1 Reinforcement Learning Algorithm . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2.2 Reward Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n2.2.3 Training Template . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n2.2.4 Performance, Self-evolution Process and Aha Moment of DeepSeek-R1-Zero 6\\n2.3 DeepSeek-R1: Reinforcement Learning with Cold Start . . . . . . . . . . . . . . . 9\\n2.3.1 Cold Start . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\\n2.3.2 Reasoning-oriented Reinforcement Learning . . . . . . . . . . . . . . . . . 10\\n2.3.3 Rejection Sampling and Supervised Fine-Tuning . . . . . . . . . . . . . . . 10\\n2.3.4 Reinforcement Learning for all Scenarios . . . . . . . . . . . . . . . . . . . 11\\n2.4 Distillation: Empower Small Models with Reasoning Capability . . . . . . . . . . 11\\n3 Experiment 11\\n3.1 DeepSeek-R1 Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\n3.2 Distilled Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\n4 Discussion 14\\n4.1 Distillation v.s. Reinforcement Learning . . . . . . . . . . . . . . . . . . . . . . . . 14\\n4.2 Unsuccessful Attempts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\n5 Conclusion, Limitations, and Future Work 16\\nA Contributions and Acknowledgments 20\\n2', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='ea0cad4c-9b02-4793-9b12-74372baa15b1', embedding=None, metadata={'page_label': '3', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='1. Introduction\\nIn recent years, Large Language Models (LLMs) have been undergoing rapid iteration and\\nevolution (Anthropic, 2024; Google, 2024; OpenAI, 2024a), progressively diminishing the gap\\ntowards Artificial General Intelligence (AGI).\\nRecently, post-training has emerged as an important component of the full training pipeline.\\nIt has been shown to enhance accuracy on reasoning tasks, align with social values, and adapt\\nto user preferences, all while requiring relatively minimal computational resources against\\npre-training. In the context of reasoning capabilities, OpenAI’s o1 (OpenAI, 2024b) series models\\nwere the first to introduce inference-time scaling by increasing the length of the Chain-of-\\nThought reasoning process. This approach has achieved significant improvements in various\\nreasoning tasks, such as mathematics, coding, and scientific reasoning. However, the challenge\\nof effective test-time scaling remains an open question for the research community. Several prior\\nworks have explored various approaches, including process-based reward models (Lightman\\net al., 2023; Uesato et al., 2022; Wang et al., 2023), reinforcement learning (Kumar et al., 2024),\\nand search algorithms such as Monte Carlo Tree Search and Beam Search (Feng et al., 2024; Trinh\\net al., 2024; Xin et al., 2024). However, none of these methods has achieved general reasoning\\nperformance comparable to OpenAI’s o1 series models.\\nIn this paper, we take the first step toward improving language model reasoning capabilities\\nusing pure reinforcement learning (RL). Our goal is to explore the potential of LLMs to develop\\nreasoning capabilities without any supervised data, focusing on their self-evolution through\\na pure RL process. Specifically, we use DeepSeek-V3-Base as the base model and employ\\nGRPO (Shao et al., 2024) as the RL framework to improve model performance in reasoning.\\nDuring training, DeepSeek-R1-Zero naturally emerged with numerous powerful and interesting\\nreasoning behaviors. After thousands of RL steps, DeepSeek-R1-Zero exhibits super performance\\non reasoning benchmarks. For instance, the pass@1 score on AIME 2024 increases from 15.6% to\\n71.0%, and with majority voting, the score further improves to 86.7%, matching the performance\\nof OpenAI-o1-0912.\\nHowever, DeepSeek-R1-Zero encounters challenges such as poor readability, and language\\nmixing. To address these issues and further enhance reasoning performance, we introduce\\nDeepSeek-R1, which incorporates a small amount of cold-start data and a multi-stage training\\npipeline. Specifically, we begin by collecting thousands of cold-start data to fine-tune the\\nDeepSeek-V3-Base model. Following this, we perform reasoning-oriented RL like DeepSeek-R1-\\nZero. Upon nearing convergence in the RL process, we create new SFT data through rejection\\nsampling on the RL checkpoint, combined with supervised data from DeepSeek-V3 in domains\\nsuch as writing, factual QA, and self-cognition, and then retrain the DeepSeek-V3-Base model.\\nAfter fine-tuning with the new data, the checkpoint undergoes an additional RL process, taking\\ninto account prompts from all scenarios. After these steps, we obtained a checkpoint referred to\\nas DeepSeek-R1, which achieves performance on par with OpenAI-o1-1217.\\nWe further explore distillation from DeepSeek-R1 to smaller dense models. Using Qwen2.5-\\n32B (Qwen, 2024b) as the base model, direct distillation from DeepSeek-R1 outperforms applying\\nRL on it. This demonstrates that the reasoning patterns discovered by larger base models are cru-\\ncial for improving reasoning capabilities. We open-source the distilled Qwen and Llama (Dubey\\net al., 2024) series. Notably, our distilled 14B model outperforms state-of-the-art open-source\\nQwQ-32B-Preview (Qwen, 2024a) by a large margin, and the distilled 32B and 70B models set a\\nnew record on the reasoning benchmarks among dense models.\\n3', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='a76c5796-ff72-40a5-8418-289ca6c695ec', embedding=None, metadata={'page_label': '4', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='1.1. Contributions\\nPost-Training: Large-Scale Reinforcement Learning on the Base Model\\n• We directly apply RL to the base model without relying on supervised fine-tuning (SFT) as\\na preliminary step. This approach allows the model to explore chain-of-thought (CoT) for\\nsolving complex problems, resulting in the development of DeepSeek-R1-Zero. DeepSeek-\\nR1-Zero demonstrates capabilities such as self-verification, reflection, and generating\\nlong CoTs, marking a significant milestone for the research community. Notably, it is the\\nfirst open research to validate that reasoning capabilities of LLMs can be incentivized\\npurely through RL, without the need for SFT. This breakthrough paves the way for future\\nadvancements in this area.\\n• We introduce our pipeline to develop DeepSeek-R1. The pipeline incorporates two RL\\nstages aimed at discovering improved reasoning patterns and aligning with human pref-\\nerences, as well as two SFT stages that serve as the seed for the model’s reasoning and\\nnon-reasoning capabilities. We believe the pipeline will benefit the industry by creating\\nbetter models.\\nDistillation: Smaller Models Can Be Powerful Too\\n• We demonstrate that the reasoning patterns of larger models can be distilled into smaller\\nmodels, resulting in better performance compared to the reasoning patterns discovered\\nthrough RL on small models. The open source DeepSeek-R1, as well as its API, will benefit\\nthe research community to distill better smaller models in the future.\\n• Using the reasoning data generated by DeepSeek-R1, we fine-tuned several dense models\\nthat are widely used in the research community. The evaluation results demonstrate that\\nthe distilled smaller dense models perform exceptionally well on benchmarks. DeepSeek-\\nR1-Distill-Qwen-7B achieves 55.5% on AIME 2024, surpassing QwQ-32B-Preview. Addi-\\ntionally, DeepSeek-R1-Distill-Qwen-32B scores 72.6% on AIME 2024, 94.3% on MATH-500,\\nand 57.2% on LiveCodeBench. These results significantly outperform previous open-\\nsource models and are comparable to o1-mini. We open-source distilled 1.5B, 7B, 8B, 14B,\\n32B, and 70B checkpoints based on Qwen2.5 and Llama3 series to the community.\\n1.2. Summary of Evaluation Results\\n• Reasoning tasks: (1) DeepSeek-R1 achieves a score of 79.8% Pass@1 on AIME 2024, slightly\\nsurpassing OpenAI-o1-1217. On MATH-500, it attains an impressive score of 97.3%,\\nperforming on par with OpenAI-o1-1217 and significantly outperforming other models. (2)\\nOn coding-related tasks, DeepSeek-R1 demonstrates expert level in code competition tasks,\\nas it achieves 2,029 Elo rating on Codeforces outperforming 96.3% human participants in\\nthe competition. For engineering-related tasks, DeepSeek-R1 performs slightly better than\\nDeepSeek-V3, which could help developers in real world tasks.\\n• Knowledge: On benchmarks such as MMLU, MMLU-Pro, and GPQA Diamond, DeepSeek-\\nR1 achieves outstanding results, significantly outperforming DeepSeek-V3 with scores\\nof 90.8% on MMLU, 84.0% on MMLU-Pro, and 71.5% on GPQA Diamond. While its\\nperformance is slightly below that of OpenAI-o1-1217 on these benchmarks, DeepSeek-R1\\nsurpasses other closed-source models, demonstrating its competitive edge in educational\\ntasks. On the factual benchmark SimpleQA, DeepSeek-R1 outperforms DeepSeek-V3,\\ndemonstrating its capability in handling fact-based queries. A similar trend is observed\\nwhere OpenAI-o1 surpasses 4o on this benchmark.\\n4', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='b238457c-3c6a-4ebc-a8b9-f2a1cbbe9327', embedding=None, metadata={'page_label': '5', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='• Others: DeepSeek-R1 also excels in a wide range of tasks, including creative writing,\\ngeneral question answering, editing, summarization, and more. It achieves an impressive\\nlength-controlled win-rate of 87.6% on AlpacaEval 2.0 and a win-rate of 92.3% on Are-\\nnaHard, showcasing its strong ability to intelligently handle non-exam-oriented queries.\\nAdditionally, DeepSeek-R1 demonstrates outstanding performance on tasks requiring\\nlong-context understanding, substantially outperforming DeepSeek-V3 on long-context\\nbenchmarks.\\n2. Approach\\n2.1. Overview\\nPrevious work has heavily relied on large amounts of supervised data to enhance model\\nperformance. In this study, we demonstrate that reasoning capabilities can be significantly\\nimproved through large-scale reinforcement learning (RL), even without using supervised\\nfine-tuning (SFT) as a cold start. Furthermore, performance can be further enhanced with\\nthe inclusion of a small amount of cold-start data. In the following sections, we present: (1)\\nDeepSeek-R1-Zero, which applies RL directly to the base model without any SFT data, and\\n(2) DeepSeek-R1, which applies RL starting from a checkpoint fine-tuned with thousands of\\nlong Chain-of-Thought (CoT) examples. 3) Distill the reasoning capability from DeepSeek-R1 to\\nsmall dense models.\\n2.2. DeepSeek-R1-Zero: Reinforcement Learning on the Base Model\\nReinforcement learning has demonstrated significant effectiveness in reasoning tasks, as ev-\\nidenced by our previous works (Shao et al., 2024; Wang et al., 2023). However, these works\\nheavily depended on supervised data, which are time-intensive to gather. In this section, we\\nexplore the potential of LLMs to develop reasoning capabilities without any supervised data,\\nfocusing on their self-evolution through a pure reinforcement learning process. We start with a\\nbrief overview of our RL algorithm, followed by the presentation of some exciting results, and\\nhope this provides the community with valuable insights.\\n2.2.1. Reinforcement Learning Algorithm\\nGroup Relative Policy OptimizationIn order to save the training costs of RL, we adopt Group\\nRelative Policy Optimization (GRPO) (Shao et al., 2024), which foregoes the critic model that is\\ntypically the same size as the policy model, and estimates the baseline from group scores instead.\\nSpecifically, for each question 𝑞, GRPO samples a group of outputs {𝑜1, 𝑜2, ··· , 𝑜𝐺}from the old\\npolicy 𝜋𝜃𝑜𝑙𝑑 and then optimizes the policy model 𝜋𝜃 by maximizing the following objective:\\nJ𝐺𝑅𝑃𝑂 (𝜃)= E[𝑞∼𝑃(𝑄), {𝑜𝑖}𝐺\\n𝑖=1 ∼𝜋𝜃𝑜𝑙𝑑 (𝑂|𝑞)]\\n1\\n𝐺\\n𝐺∑︁\\n𝑖=1\\n\\x12\\nmin\\n\\x12 𝜋𝜃(𝑜𝑖|𝑞)\\n𝜋𝜃𝑜𝑙𝑑 (𝑜𝑖|𝑞)𝐴𝑖, clip\\n\\x12 𝜋𝜃(𝑜𝑖|𝑞)\\n𝜋𝜃𝑜𝑙𝑑 (𝑜𝑖|𝑞), 1−𝜀, 1+𝜀\\n\\x13\\n𝐴𝑖\\n\\x13\\n−𝛽D𝐾𝐿\\n\\x00\\n𝜋𝜃||𝜋𝑟𝑒𝑓\\n\\x01\\x13\\n, (1)\\nD𝐾𝐿\\n\\x00\\n𝜋𝜃||𝜋𝑟𝑒𝑓\\n\\x01 =\\n𝜋𝑟𝑒𝑓 (𝑜𝑖|𝑞)\\n𝜋𝜃(𝑜𝑖|𝑞) −log\\n𝜋𝑟𝑒𝑓 (𝑜𝑖|𝑞)\\n𝜋𝜃(𝑜𝑖|𝑞) −1, (2)\\nwhere 𝜀 and 𝛽 are hyper-parameters, and 𝐴𝑖 is the advantage, computed using a group of\\nrewards {𝑟1, 𝑟2, ... , 𝑟𝐺}corresponding to the outputs within each group:\\n𝐴𝑖 = 𝑟𝑖 −m𝑒𝑎𝑛({𝑟1, 𝑟2, ··· , 𝑟𝐺})\\ns𝑡𝑑({𝑟1, 𝑟2, ··· , 𝑟𝐺}) . (3)\\n5', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='84463a2c-043a-4f26-88a4-893e6afd4ca6', embedding=None, metadata={'page_label': '6', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\\nThe assistant first thinks about the reasoning process in the mind and then provides the user\\nwith the answer. The reasoning process and answer are enclosed within <think> </think> and\\n<answer> </answer> tags, respectively, i.e., <think> reasoning process here </think>\\n<answer> answer here </answer>. User: prompt. Assistant:\\nTable 1 |Template for DeepSeek-R1-Zero. prompt will be replaced with the specific reasoning\\nquestion during training.\\n2.2.2. Reward Modeling\\nThe reward is the source of the training signal, which decides the optimization direction of RL.\\nTo train DeepSeek-R1-Zero, we adopt a rule-based reward system that mainly consists of two\\ntypes of rewards:\\n• Accuracy rewards: The accuracy reward model evaluates whether the response is correct.\\nFor example, in the case of math problems with deterministic results, the model is required\\nto provide the final answer in a specified format (e.g., within a box), enabling reliable\\nrule-based verification of correctness. Similarly, for LeetCode problems, a compiler can be\\nused to generate feedback based on predefined test cases.\\n• Format rewards: In addition to the accuracy reward model, we employ a format reward\\nmodel that enforces the model to put its thinking process between ‘<think>’ and ‘</think>’\\ntags.\\nWe do not apply the outcome or process neural reward model in developing DeepSeek-R1-Zero,\\nbecause we find that the neural reward model may suffer from reward hacking in the large-scale\\nreinforcement learning process, and retraining the reward model needs additional training\\nresources and it complicates the whole training pipeline.\\n2.2.3. Training Template\\nTo train DeepSeek-R1-Zero, we begin by designing a straightforward template that guides\\nthe base model to adhere to our specified instructions. As depicted in Table 1, this template\\nrequires DeepSeek-R1-Zero to first produce a reasoning process, followed by the final answer.\\nWe intentionally limit our constraints to this structural format, avoiding any content-specific\\nbiases—such as mandating reflective reasoning or promoting particular problem-solving strate-\\ngies—to ensure that we can accurately observe the model’s natural progression during the RL\\nprocess.\\n2.2.4. Performance, Self-evolution Process and Aha Moment of DeepSeek-R1-Zero\\nPerformance of DeepSeek-R1-Zero Figure 2 depicts the performance trajectory of DeepSeek-\\nR1-Zero on the AIME 2024 benchmark throughout the RL training process. As illustrated,\\nDeepSeek-R1-Zero demonstrates a steady and consistent enhancement in performance as the\\nRL training advances. Notably, the average pass@1 score on AIME 2024 shows a significant\\nincrease, jumping from an initial 15.6% to an impressive 71.0%, reaching performance levels\\ncomparable to OpenAI-o1-0912. This significant improvement highlights the efficacy of our RL\\nalgorithm in optimizing the model’s performance over time.\\nTable 2 provides a comparative analysis between DeepSeek-R1-Zero and OpenAI’s o1-0912\\nmodels across a variety of reasoning-related benchmarks. The findings reveal that RL empowers\\n6', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='19c9542e-e297-4c9b-bf35-76986b99b5fe', embedding=None, metadata={'page_label': '7', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Model AIME 2024 MATH-500 GPQA LiveCode CodeForcesDiamond Bench\\npass@1 cons@64 pass@1 pass@1 pass@1 rating\\nOpenAI-o1-mini 63.6 80.0 90.0 60.0 53.8 1820\\nOpenAI-o1-0912 74.4 83.3 94.8 77.3 63.4 1843\\nDeepSeek-R1-Zero 71.0 86.7 95.9 73.3 50.0 1444\\nTable 2 |Comparison of DeepSeek-R1-Zero and OpenAI o1 models on reasoning-related\\nbenchmarks.\\nFigure 2 |AIME accuracy of DeepSeek-R1-Zero during training. For each question, we sample\\n16 responses and calculate the overall average accuracy to ensure a stable evaluation.\\nDeepSeek-R1-Zero to attain robust reasoning capabilities without the need for any supervised\\nfine-tuning data. This is a noteworthy achievement, as it underscores the model’s ability to\\nlearn and generalize effectively through RL alone. Additionally, the performance of DeepSeek-\\nR1-Zero can be further augmented through the application of majority voting. For example,\\nwhen majority voting is employed on the AIME benchmark, DeepSeek-R1-Zero’s performance\\nescalates from 71.0% to 86.7%, thereby exceeding the performance of OpenAI-o1-0912. The\\nability of DeepSeek-R1-Zero to achieve such competitive performance, both with and without\\nmajority voting, highlights its strong foundational capabilities and its potential for further\\nadvancements in reasoning tasks.\\nSelf-evolution Process of DeepSeek-R1-ZeroThe self-evolution process of DeepSeek-R1-Zero\\nis a fascinating demonstration of how RL can drive a model to improve its reasoning capabilities\\nautonomously. By initiating RL directly from the base model, we can closely monitor the model’s\\nprogression without the influence of the supervised fine-tuning stage. This approach provides\\na clear view of how the model evolves over time, particularly in terms of its ability to handle\\ncomplex reasoning tasks.\\nAs depicted in Figure 3, the thinking time of DeepSeek-R1-Zero shows consistent improve-\\n7', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='5ca00b3e-11a6-49f8-ab83-384201d701be', embedding=None, metadata={'page_label': '8', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Figure 3 |The average response length of DeepSeek-R1-Zero on the training set during the RL\\nprocess. DeepSeek-R1-Zero naturally learns to solve reasoning tasks with more thinking time.\\nment throughout the training process. This improvement is not the result of external adjustments\\nbut rather an intrinsic development within the model. DeepSeek-R1-Zero naturally acquires the\\nability to solve increasingly complex reasoning tasks by leveraging extended test-time compu-\\ntation. This computation ranges from generating hundreds to thousands of reasoning tokens,\\nallowing the model to explore and refine its thought processes in greater depth.\\nOne of the most remarkable aspects of this self-evolution is the emergence of sophisticated\\nbehaviors as the test-time computation increases. Behaviors such as reflection—where the model\\nrevisits and reevaluates its previous steps—and the exploration of alternative approaches to\\nproblem-solving arise spontaneously. These behaviors are not explicitly programmed but instead\\nemerge as a result of the model’s interaction with the reinforcement learning environment. This\\nspontaneous development significantly enhances DeepSeek-R1-Zero’s reasoning capabilities,\\nenabling it to tackle more challenging tasks with greater efficiency and accuracy.\\nAha Moment of DeepSeek-R1-ZeroA particularly intriguing phenomenon observed during\\nthe training of DeepSeek-R1-Zero is the occurrence of an “aha moment”. This moment, as\\nillustrated in Table 3, occurs in an intermediate version of the model. During this phase,\\nDeepSeek-R1-Zero learns to allocate more thinking time to a problem by reevaluating its initial\\napproach. This behavior is not only a testament to the model’s growing reasoning abilities\\nbut also a captivating example of how reinforcement learning can lead to unexpected and\\nsophisticated outcomes.\\nThis moment is not only an “aha moment” for the model but also for the researchers\\nobserving its behavior. It underscores the power and beauty of reinforcement learning: rather\\nthan explicitly teaching the model on how to solve a problem, we simply provide it with the\\nright incentives, and it autonomously develops advanced problem-solving strategies. The\\n“aha moment” serves as a powerful reminder of the potential of RL to unlock new levels of\\nintelligence in artificial systems, paving the way for more autonomous and adaptive models in\\nthe future.\\n8', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='b8f6c6f2-762f-4b56-8de9-b095fe77f33c', embedding=None, metadata={'page_label': '9', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Question: If 𝑎 >1, then the sum of the real solutions of\\n√︁\\n𝑎−√\\n𝑎+𝑥 = 𝑥 is equal to\\nResponse: <think>\\nTo solve the equation\\n√︁\\n𝑎−√\\n𝑎+𝑥 = 𝑥, let’s start by squaring both ···\\x10√︁\\n𝑎−√\\n𝑎+𝑥\\n\\x112\\n= 𝑥2 =⇒ 𝑎−√\\n𝑎+𝑥 = 𝑥2.\\nRearrange to isolate the inner square root term:\\n(𝑎−𝑥2)2 = 𝑎+𝑥 =⇒ 𝑎2 −2𝑎𝑥2 +(𝑥2)2 = 𝑎+𝑥 =⇒ 𝑥4 −2𝑎𝑥2 −𝑥+(𝑎2 −𝑎)= 0\\n. . .\\nWait, wait. Wait. That’s an aha moment I can flag here.\\nLet’s reevaluate this step-by-step to identify if the correct sum can be ···\\nWe started with the equation:√︁\\n𝑎−√\\n𝑎+𝑥 = 𝑥\\nFirst, let’s square both sides:\\n𝑎−√\\n𝑎+𝑥 = 𝑥2 =⇒ √\\n𝑎+𝑥 = 𝑎−𝑥2\\nNext, I could square both sides again, treating the equation: ···\\n. . .\\nTable 3 |An interesting “aha moment” of an intermediate version of DeepSeek-R1-Zero. The\\nmodel learns to rethink using an anthropomorphic tone. This is also an aha moment for us,\\nallowing us to witness the power and beauty of reinforcement learning.\\nDrawback of DeepSeek-R1-Zero Although DeepSeek-R1-Zero exhibits strong reasoning\\ncapabilities and autonomously develops unexpected and powerful reasoning behaviors, it faces\\nseveral issues. For instance, DeepSeek-R1-Zero struggles with challenges like poor readability,\\nand language mixing. To make reasoning processes more readable and share them with the\\nopen community, we explore DeepSeek-R1, a method that utilizes RL with human-friendly\\ncold-start data.\\n2.3. DeepSeek-R1: Reinforcement Learning with Cold Start\\nInspired by the promising results of DeepSeek-R1-Zero, two natural questions arise: 1) Can\\nreasoning performance be further improved or convergence accelerated by incorporating a small\\namount of high-quality data as a cold start? 2) How can we train a user-friendly model that\\nnot only produces clear and coherent Chains of Thought (CoT) but also demonstrates strong\\ngeneral capabilities? To address these questions, we design a pipeline to train DeepSeek-R1. The\\npipeline consists of four stages, outlined as follows.\\n2.3.1. Cold Start\\nUnlike DeepSeek-R1-Zero, to prevent the early unstable cold start phase of RL training from\\nthe base model, for DeepSeek-R1 we construct and collect a small amount of long CoT data\\nto fine-tune the model as the initial RL actor. To collect such data, we have explored several\\napproaches: using few-shot prompting with a long CoT as an example, directly prompting\\nmodels to generate detailed answers with reflection and verification, gathering DeepSeek-R1-\\nZero outputs in a readable format, and refining the results through post-processing by human\\nannotators.\\nIn this work, we collect thousands of cold-start data to fine-tune the DeepSeek-V3-Base as\\nthe starting point for RL. Compared to DeepSeek-R1-Zero, the advantages of cold start data\\n9', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='4164f94e-feb6-458c-8166-1a7c6a24f249', embedding=None, metadata={'page_label': '10', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='include:\\n• Readability: A key limitation of DeepSeek-R1-Zero is that its content is often not suitable\\nfor reading. Responses may mix multiple languages or lack markdown formatting to\\nhighlight answers for users. In contrast, when creating cold-start data for DeepSeek-R1,\\nwe design a readable pattern that includes a summary at the end of each response and\\nfilters out responses that are not reader-friendly. Here, we define the output format as\\n|special_token|<reasoning_process>|special_token|<summary>, where the reasoning\\nprocess is the CoT for the query, and the summary is used to summarize the reasoning\\nresults.\\n• Potential: By carefully designing the pattern for cold-start data with human priors, we\\nobserve better performance against DeepSeek-R1-Zero. We believe the iterative training is\\na better way for reasoning models.\\n2.3.2. Reasoning-oriented Reinforcement Learning\\nAfter fine-tuning DeepSeek-V3-Base on the cold start data, we apply the same large-scale\\nreinforcement learning training process as employed in DeepSeek-R1-Zero. This phase focuses\\non enhancing the model’s reasoning capabilities, particularly in reasoning-intensive tasks such\\nas coding, mathematics, science, and logic reasoning, which involve well-defined problems with\\nclear solutions. During the training process, we observe that CoT often exhibits language mixing,\\nparticularly when RL prompts involve multiple languages. To mitigate the issue of language\\nmixing, we introduce a language consistency reward during RL training, which is calculated\\nas the proportion of target language words in the CoT. Although ablation experiments show\\nthat such alignment results in a slight degradation in the model’s performance, this reward\\naligns with human preferences, making it more readable. Finally, we combine the accuracy of\\nreasoning tasks and the reward for language consistency by directly summing them to form the\\nfinal reward. We then apply RL training on the fine-tuned model until it achieves convergence\\non reasoning tasks.\\n2.3.3. Rejection Sampling and Supervised Fine-Tuning\\nWhen reasoning-oriented RL converges, we utilize the resulting checkpoint to collect SFT\\n(Supervised Fine-Tuning) data for the subsequent round. Unlike the initial cold-start data, which\\nprimarily focuses on reasoning, this stage incorporates data from other domains to enhance the\\nmodel’s capabilities in writing, role-playing, and other general-purpose tasks. Specifically, we\\ngenerate the data and fine-tune the model as described below.\\nReasoning data We curate reasoning prompts and generate reasoning trajectories by perform-\\ning rejection sampling from the checkpoint from the above RL training. In the previous stage,\\nwe only included data that could be evaluated using rule-based rewards. However, in this stage,\\nwe expand the dataset by incorporating additional data, some of which use a generative reward\\nmodel by feeding the ground-truth and model predictions into DeepSeek-V3 for judgment.\\nAdditionally, because the model output is sometimes chaotic and difficult to read, we have\\nfiltered out chain-of-thought with mixed languages, long parapraphs, and code blocks. For\\neach prompt, we sample multiple responses and retain only the correct ones. In total, we collect\\nabout 600k reasoning related training samples.\\n10', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='c1df4c79-7463-4e58-a815-dacd129e0b3c', embedding=None, metadata={'page_label': '11', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Non-Reasoning data For non-reasoning data, such as writing, factual QA, self-cognition,\\nand translation, we adopt the DeepSeek-V3 pipeline and reuse portions of the SFT dataset of\\nDeepSeek-V3. For certain non-reasoning tasks, we call DeepSeek-V3 to generate a potential\\nchain-of-thought before answering the question by prompting. However, for simpler queries,\\nsuch as “hello” we do not provide a CoT in response. In the end, we collected a total of\\napproximately 200k training samples that are unrelated to reasoning.\\nWe fine-tune DeepSeek-V3-Base for two epochs using the above curated dataset of about\\n800k samples.\\n2.3.4. Reinforcement Learning for all Scenarios\\nTo further align the model with human preferences, we implement a secondary reinforcement\\nlearning stage aimed at improving the model’s helpfulness and harmlessness while simultane-\\nously refining its reasoning capabilities. Specifically, we train the model using a combination\\nof reward signals and diverse prompt distributions. For reasoning data, we adhere to the\\nmethodology outlined in DeepSeek-R1-Zero, which utilizes rule-based rewards to guide the\\nlearning process in math, code, and logical reasoning domains. For general data, we resort to\\nreward models to capture human preferences in complex and nuanced scenarios. We build\\nupon the DeepSeek-V3 pipeline and adopt a similar distribution of preference pairs and train-\\ning prompts. For helpfulness, we focus exclusively on the final summary, ensuring that the\\nassessment emphasizes the utility and relevance of the response to the user while minimizing\\ninterference with the underlying reasoning process. For harmlessness, we evaluate the entire\\nresponse of the model, including both the reasoning process and the summary, to identify and\\nmitigate any potential risks, biases, or harmful content that may arise during the generation\\nprocess. Ultimately, the integration of reward signals and diverse data distributions enables us\\nto train a model that excels in reasoning while prioritizing helpfulness and harmlessness.\\n2.4. Distillation: Empower Small Models with Reasoning Capability\\nTo equip more efficient smaller models with reasoning capabilities like DeepSeek-R1, we directly\\nfine-tuned open-source models like Qwen (Qwen, 2024b) and Llama (AI@Meta, 2024) using\\nthe 800k samples curated with DeepSeek-R1, as detailed in §2.3.3. Our findings indicate that\\nthis straightforward distillation method significantly enhances the reasoning abilities of smaller\\nmodels. The base models we use here are Qwen2.5-Math-1.5B, Qwen2.5-Math-7B, Qwen2.5-\\n14B, Qwen2.5-32B, Llama-3.1-8B, and Llama-3.3-70B-Instruct. We select Llama-3.3 because its\\nreasoning capability is slightly better than that of Llama-3.1.\\nFor distilled models, we apply only SFT and do not include an RL stage, even though\\nincorporating RL could substantially boost model performance. Our primary goal here is to\\ndemonstrate the effectiveness of the distillation technique, leaving the exploration of the RL\\nstage to the broader research community.\\n3. Experiment\\nBenchmarks We evaluate models on MMLU (Hendrycks et al., 2020), MMLU-Redux (Gema\\net al., 2024), MMLU-Pro (Wang et al., 2024), C-Eval (Huang et al., 2023), and CMMLU (Li et al.,\\n2023), IFEval (Zhou et al., 2023), FRAMES (Krishna et al., 2024), GPQA Diamond (Rein et al.,\\n2023), SimpleQA (OpenAI, 2024c), C-SimpleQA (He et al., 2024), SWE-Bench Verified (OpenAI,\\n11', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='6dfc7e92-ff2b-44ed-ab40-f330d2a0e892', embedding=None, metadata={'page_label': '12', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='2024d), Aider 1, LiveCodeBench (Jain et al., 2024) (2024-08 – 2025-01), Codeforces 2, Chinese\\nNational High School Mathematics Olympiad (CNMO 2024)3, and American Invitational Math-\\nematics Examination 2024 (AIME 2024) (MAA, 2024). In addition to standard benchmarks, we\\nalso evaluate our models on open-ended generation tasks using LLMs as judges. Specifically, we\\nadhere to the original configurations of AlpacaEval 2.0 (Dubois et al., 2024) and Arena-Hard (Li\\net al., 2024), which leverage GPT-4-Turbo-1106 as judges for pairwise comparisons. Here, we\\nonly feed the final summary to evaluation to avoid the length bias. For distilled models, we\\nreport representative results on AIME 2024, MATH-500, GPQA Diamond, Codeforces, and\\nLiveCodeBench.\\nEvaluation Prompts Following the setup in DeepSeek-V3, standard benchmarks such as\\nMMLU, DROP , GPQA Diamond, and SimpleQA are evaluated using prompts from the simple-\\nevals framework. For MMLU-Redux, we adopt the Zero-Eval prompt format (Lin, 2024) in a\\nzero-shot setting. In terms of MMLU-Pro, C-Eval and CLUE-WSC, since the original prompts\\nare few-shot, we slightly modify the prompt to the zero-shot setting. The CoT in few-shot\\nmay hurt the performance of DeepSeek-R1. Other datasets follow their original evaluation\\nprotocols with default prompts provided by their creators. For code and math benchmarks, the\\nHumanEval-Mul dataset covers eight mainstream programming languages (Python, Java, C++,\\nC#, JavaScript, TypeScript, PHP , and Bash). Model performance on LiveCodeBench is evaluated\\nusing CoT format, with data collected between August 2024 and January 2025. The Codeforces\\ndataset is evaluated using problems from 10 Div.2 contests along with expert-crafted test cases,\\nafter which the expected ratings and percentages of competitors are calculated. SWE-Bench\\nverified results are obtained via the agentless framework (Xia et al., 2024). AIDER-related\\nbenchmarks are measured using a \"diff\" format. DeepSeek-R1 outputs are capped at a maximum\\nof 32,768 tokens for each benchmark.\\nBaselines We conduct comprehensive evaluations against several strong baselines, including\\nDeepSeek-V3, Claude-Sonnet-3.5-1022, GPT-4o-0513, OpenAI-o1-mini, and OpenAI-o1-1217.\\nSince accessing the OpenAI-o1-1217 API is challenging in mainland China, we report its perfor-\\nmance based on official reports. For distilled models, we also compare the open-source model\\nQwQ-32B-Preview (Qwen, 2024a).\\nEvaluation Setup We set the maximum generation length to 32,768 tokens for the models.\\nWe found that using greedy decoding to evaluate long-output reasoning models results in\\nhigher repetition rates and significant variability across different checkpoints. Therefore, we\\ndefault to pass@𝑘evaluation (Chen et al., 2021) and report pass@1 using a non-zero temperature.\\nSpecifically, we use a sampling temperature of 0.6 and a top- 𝑝 value of 0.95 to generate 𝑘\\nresponses (typically between 4 and 64, depending on the test set size) for each question. Pass@1\\nis then calculated as\\npass@1 = 1\\n𝑘\\n𝑘∑︁\\n𝑖=1\\n𝑝𝑖,\\nwhere 𝑝𝑖 denotes the correctness of the 𝑖-th response. This method provides more reliable\\nperformance estimates. For AIME 2024, we also report consensus (majority vote) results (Wang\\net al., 2022) using 64 samples, denoted as cons@64.\\n1https://aider.chat\\n2https://codeforces.com\\n3https://www.cms.org.cn/Home/comp/comp/cid/12.html\\n12', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='51266250-1fbb-4c08-9135-a26acc217b04', embedding=None, metadata={'page_label': '13', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='3.1. DeepSeek-R1 Evaluation\\nBenchmark (Metric)\\nClaude-3.5- GPT-4o DeepSeek OpenAI OpenAI DeepSeek\\nSonnet-1022 0513 V3 o1-mini o1-1217 R1\\nArchitecture - - MoE - - MoE\\n# Activated Params - - 37B - - 37B\\n# Total Params - - 671B - - 671B\\nEnglish\\nMMLU (Pass@1) 88.3 87.2 88.5 85.2 91.8 90.8\\nMMLU-Redux (EM) 88.9 88.0 89.1 86.7 - 92.9\\nMMLU-Pro (EM) 78.0 72.6 75.9 80.3 - 84.0\\nDROP (3-shot F1) 88.3 83.7 91.6 83.9 90.2 92.2\\nIF-Eval (Prompt Strict) 86.5 84.3 86.1 84.8 - 83.3\\nGPQA Diamond (Pass@1) 65.0 49.9 59.1 60.0 75.7 71.5\\nSimpleQA (Correct) 28.4 38.2 24.9 7.0 47.0 30.1\\nFRAMES (Acc.) 72.5 80.5 73.3 76.9 - 82.5\\nAlpacaEval2.0 (LC-winrate) 52.0 51.1 70.0 57.8 - 87.6\\nArenaHard (GPT-4-1106) 85.2 80.4 85.5 92.0 - 92.3\\nCode\\nLiveCodeBench (Pass@1-COT) 38.9 32.9 36.2 53.8 63.4 65.9\\nCodeforces (Percentile) 20.3 23.6 58.7 93.4 96.6 96.3\\nCodeforces (Rating) 717 759 1134 1820 2061 2029\\nSWE Verified (Resolved) 50.8 38.8 42.0 41.6 48.9 49.2\\nAider-Polyglot (Acc.) 45.3 16.0 49.6 32.9 61.7 53.3\\nMath\\nAIME 2024 (Pass@1) 16.0 9.3 39.2 63.6 79.2 79.8\\nMATH-500 (Pass@1) 78.3 74.6 90.2 90.0 96.4 97.3\\nCNMO 2024 (Pass@1) 13.1 10.8 43.2 67.6 - 78.8\\nChinese\\nCLUEWSC (EM) 85.4 87.9 90.9 89.9 - 92.8\\nC-Eval (EM) 76.7 76.0 86.5 68.9 - 91.8\\nC-SimpleQA (Correct) 55.4 58.7 68.0 40.3 - 63.7\\nTable 4 |Comparison between DeepSeek-R1 and other representative models.\\nFor education-oriented knowledge benchmarks such as MMLU, MMLU-Pro, and GPQA\\nDiamond, DeepSeek-R1 demonstrates superior performance compared to DeepSeek-V3. This im-\\nprovement is primarily attributed to enhanced accuracy in STEM-related questions, where signif-\\nicant gains are achieved through large-scale reinforcement learning. Additionally, DeepSeek-R1\\nexcels on FRAMES, a long-context-dependent QA task, showcasing its strong document analysis\\ncapabilities. This highlights the potential of reasoning models in AI-driven search and data\\nanalysis tasks. On the factual benchmark SimpleQA, DeepSeek-R1 outperforms DeepSeek-V3,\\ndemonstrating its capability in handling fact-based queries. A similar trend is observed where\\nOpenAI-o1 surpasses GPT-4o on this benchmark. However, DeepSeek-R1 performs worse than\\nDeepSeek-V3 on the Chinese SimpleQA benchmark, primarily due to its tendency to refuse\\nanswering certain queries after safety RL. Without safety RL, DeepSeek-R1 could achieve an\\naccuracy of over 70%.\\nDeepSeek-R1 also delivers impressive results on IF-Eval, a benchmark designed to assess a\\nmodel’s ability to follow format instructions. These improvements can be linked to the inclusion\\nof instruction-following data during the final stages of supervised fine-tuning (SFT) and RL\\ntraining. Furthermore, remarkable performance is observed on AlpacaEval2.0 and ArenaHard,\\nindicating DeepSeek-R1’s strengths in writing tasks and open-domain question answering. Its\\nsignificant outperformance of DeepSeek-V3 underscores the generalization benefits of large-scale\\nRL, which not only boosts reasoning capabilities but also improves performance across diverse\\ndomains. Moreover, the summary lengths generated by DeepSeek-R1 are concise, with an\\naverage of 689 tokens on ArenaHard and 2,218 characters on AlpacaEval 2.0. This indicates that\\n13', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='2d4d4ea7-240b-4138-8260-4b9359659818', embedding=None, metadata={'page_label': '14', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='DeepSeek-R1 avoids introducing length bias during GPT-based evaluations, further solidifying\\nits robustness across multiple tasks.\\nOn math tasks, DeepSeek-R1 demonstrates performance on par with OpenAI-o1-1217,\\nsurpassing other models by a large margin. A similar trend is observed on coding algorithm\\ntasks, such as LiveCodeBench and Codeforces, where reasoning-focused models dominate these\\nbenchmarks. On engineering-oriented coding tasks, OpenAI-o1-1217 outperforms DeepSeek-R1\\non Aider but achieves comparable performance on SWE Verified. We believe the engineering\\nperformance of DeepSeek-R1 will improve in the next version, as the amount of related RL\\ntraining data currently remains very limited.\\n3.2. Distilled Model Evaluation\\nModel AIME 2024 MATH-500 GPQA LiveCode CodeForcesDiamond Bench\\npass@1 cons@64 pass@1 pass@1 pass@1 rating\\nGPT-4o-0513 9.3 13.4 74.6 49.9 32.9 759\\nClaude-3.5-Sonnet-1022 16.0 26.7 78.3 65.0 38.9 717\\nOpenAI-o1-mini 63.6 80.0 90.0 60.0 53.8 1820\\nQwQ-32B-Preview 50.0 60.0 90.6 54.5 41.9 1316\\nDeepSeek-R1-Distill-Qwen-1.5B28.9 52.7 83.9 33.8 16.9 954\\nDeepSeek-R1-Distill-Qwen-7B 55.5 83.3 92.8 49.1 37.6 1189\\nDeepSeek-R1-Distill-Qwen-14B69.7 80.0 93.9 59.1 53.1 1481\\nDeepSeek-R1-Distill-Qwen-32B 72.6 83.3 94.3 62.1 57.2 1691\\nDeepSeek-R1-Distill-Llama-8B 50.4 80.0 89.1 49.0 39.6 1205\\nDeepSeek-R1-Distill-Llama-70B70.0 86.7 94.5 65.2 57.5 1633\\nTable 5 |Comparison of DeepSeek-R1 distilled models and other comparable models on\\nreasoning-related benchmarks.\\nAs shown in Table 5, simply distilling DeepSeek-R1’s outputs enables the efficient DeepSeek-\\nR1-7B (i.e., DeepSeek-R1-Distill-Qwen-7B, abbreviated similarly below) to outperform non-\\nreasoning models like GPT-4o-0513 across the board. DeepSeek-R1-14B surpasses QwQ-32B-\\nPreview on all evaluation metrics, while DeepSeek-R1-32B and DeepSeek-R1-70B significantly\\nexceed o1-mini on most benchmarks. These results demonstrate the strong potential of distilla-\\ntion. Additionally, we found that applying RL to these distilled models yields significant further\\ngains. We believe this warrants further exploration and therefore present only the results of the\\nsimple SFT-distilled models here.\\n4. Discussion\\n4.1. Distillation v.s. Reinforcement Learning\\nIn Section 3.2, we can see that by distilling DeepSeek-R1, the small model can achieve impressive\\nresults. However, there is still one question left: can the model achieve comparable performance\\nthrough the large-scale RL training discussed in the paper without distillation?\\nTo answer this question, we conduct large-scale RL training on Qwen-32B-Base using math,\\ncode, and STEM data, training for over 10K steps, resulting in DeepSeek-R1-Zero-Qwen-32B. The\\nexperimental results, shown in Table 6, demonstrate that the 32B base model, after large-scale\\n14', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='01743ae3-d36f-416b-a485-66a195a80c4c', embedding=None, metadata={'page_label': '15', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Model\\nAIME 2024 MATH-500 GPQA Diamond LiveCodeBench\\npass@1 cons@64 pass@1 pass@1 pass@1\\nQwQ-32B-Preview 50.0 60.0 90.6 54.5 41.9\\nDeepSeek-R1-Zero-Qwen-32B 47.0 60.0 91.6 55.0 40.2\\nDeepSeek-R1-Distill-Qwen-32B 72.6 83.3 94.3 62.1 57.2\\nTable 6 |Comparison of distilled and RL Models on Reasoning-Related Benchmarks.\\nRL training, achieves performance on par with QwQ-32B-Preview. However, DeepSeek-R1-\\nDistill-Qwen-32B, which is distilled from DeepSeek-R1, performs significantly better than\\nDeepSeek-R1-Zero-Qwen-32B across all benchmarks.\\nTherefore, we can draw two conclusions: First, distilling more powerful models into smaller\\nones yields excellent results, whereas smaller models relying on the large-scale RL mentioned in\\nthis paper require enormous computational power and may not even achieve the performance\\nof distillation. Second, while distillation strategies are both economical and effective, advancing\\nbeyond the boundaries of intelligence may still require more powerful base models and larger-\\nscale reinforcement learning.\\n4.2. Unsuccessful Attempts\\nIn the early stages of developing DeepSeek-R1, we also encountered failures and setbacks along\\nthe way. We share our failure experiences here to provide insights, but this does not imply that\\nthese approaches are incapable of developing effective reasoning models.\\nProcess Reward Model (PRM)PRM is a reasonable method to guide the model toward better\\napproaches for solving reasoning tasks (Lightman et al., 2023; Uesato et al., 2022; Wang et al.,\\n2023). However, in practice, PRM has three main limitations that may hinder its ultimate suc-\\ncess. First, it is challenging to explicitly define a fine-grain step in general reasoning. Second,\\ndetermining whether the current intermediate step is correct is a challenging task. Automated\\nannotation using models may not yield satisfactory results, while manual annotation is not con-\\nducive to scaling up. Third, once a model-based PRM is introduced, it inevitably leads to reward\\nhacking (Gao et al., 2022), and retraining the reward model needs additional training resources\\nand it complicates the whole training pipeline. In conclusion, while PRM demonstrates a good\\nability to rerank the top-N responses generated by the model or assist in guided search (Snell\\net al., 2024), its advantages are limited compared to the additional computational overhead it\\nintroduces during the large-scale reinforcement learning process in our experiments.\\nMonte Carlo Tree Search (MCTS)Inspired by AlphaGo (Silver et al., 2017b) and AlphaZero (Sil-\\nver et al., 2017a), we explored using Monte Carlo Tree Search (MCTS) to enhance test-time\\ncompute scalability. This approach involves breaking answers into smaller parts to allow the\\nmodel to explore the solution space systematically. To facilitate this, we prompt the model to\\ngenerate multiple tags that correspond to specific reasoning steps necessary for the search. For\\ntraining, we first use collected prompts to find answers via MCTS guided by a pre-trained value\\nmodel. Subsequently, we use the resulting question-answer pairs to train both the actor model\\nand the value model, iteratively refining the process.\\nHowever, this approach encounters several challenges when scaling up the training. First,\\nunlike chess, where the search space is relatively well-defined, token generation presents an\\n15', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='51d97e71-d896-43d6-b1e0-efab4a1999d5', embedding=None, metadata={'page_label': '16', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='exponentially larger search space. To address this, we set a maximum extension limit for each\\nnode, but this can lead to the model getting stuck in local optima. Second, the value model\\ndirectly influences the quality of generation since it guides each step of the search process.\\nTraining a fine-grained value model is inherently difficult, which makes it challenging for the\\nmodel to iteratively improve. While AlphaGo’s core success relied on training a value model to\\nprogressively enhance its performance, this principle proves difficult to replicate in our setup\\ndue to the complexities of token generation.\\nIn conclusion, while MCTS can improve performance during inference when paired with a\\npre-trained value model, iteratively boosting model performance through self-search remains a\\nsignificant challenge.\\n5. Conclusion, Limitations, and Future Work\\nIn this work, we share our journey in enhancing model reasoning abilities through reinforcement\\nlearning. DeepSeek-R1-Zero represents a pure RL approach without relying on cold-start\\ndata, achieving strong performance across various tasks. DeepSeek-R1 is more powerful,\\nleveraging cold-start data alongside iterative RL fine-tuning. Ultimately, DeepSeek-R1 achieves\\nperformance comparable to OpenAI-o1-1217 on a range of tasks.\\nWe further explore distillation the reasoning capability to small dense models. We use\\nDeepSeek-R1 as the teacher model to generate 800K training samples, and fine-tune several small\\ndense models. The results are promising: DeepSeek-R1-Distill-Qwen-1.5B outperforms GPT-4o\\nand Claude-3.5-Sonnet on math benchmarks with 28.9% on AIME and 83.9% on MATH. Other\\ndense models also achieve impressive results, significantly outperforming other instruction-\\ntuned models based on the same underlying checkpoints.\\nIn the future, we plan to invest in research across the following directions for DeepSeek-R1.\\n• General Capability:Currently, the capabilities of DeepSeek-R1 fall short of DeepSeek-V3\\nin tasks such as function calling, multi-turn, complex role-playing, and JSON output.\\nMoving forward, we plan to explore how long CoT can be leveraged to enhance tasks in\\nthese fields.\\n• Language Mixing:DeepSeek-R1 is currently optimized for Chinese and English, which\\nmay result in language mixing issues when handling queries in other languages. For\\ninstance, DeepSeek-R1 might use English for reasoning and responses, even if the query is\\nin a language other than English or Chinese. We aim to address this limitation in future\\nupdates.\\n• Prompting Engineering:When evaluating DeepSeek-R1, we observe that it is sensitive\\nto prompts. Few-shot prompting consistently degrades its performance. Therefore, we\\nrecommend users directly describe the problem and specify the output format using a\\nzero-shot setting for optimal results.\\n• Software Engineering Tasks:Due to the long evaluation times, which impact the effi-\\nciency of the RL process, large-scale RL has not been applied extensively in software\\nengineering tasks. As a result, DeepSeek-R1 has not demonstrated a huge improvement\\nover DeepSeek-V3 on software engineering benchmarks. Future versions will address\\nthis by implementing rejection sampling on software engineering data or incorporating\\nasynchronous evaluations during the RL process to improve efficiency.\\n16', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='1b847b11-3d3b-4845-8dd9-e7021fba69de', embedding=None, metadata={'page_label': '17', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='References\\nAI@Meta. Llama 3.1 model card, 2024. URL https://github.com/meta-llama/llama-m\\nodels/blob/main/models/llama3_1/MODEL_CARD.md.\\nAnthropic. Claude 3.5 sonnet, 2024. URL https://www.anthropic.com/news/claude-3\\n-5-sonnet.\\nM. Chen, J. Tworek, H. Jun, Q. Yuan, H. P . de Oliveira Pinto, J. Kaplan, H. Edwards, Y. Burda,\\nN. Joseph, G. Brockman, A. Ray, R. Puri, G. Krueger, M. Petrov, H. Khlaaf, G. Sastry, P . Mishkin,\\nB. Chan, S. Gray, N. Ryder, M. Pavlov, A. Power, L. Kaiser, M. Bavarian, C. Winter, P . Tillet,\\nF. P . Such, D. Cummings, M. Plappert, F. Chantzis, E. Barnes, A. Herbert-Voss, W. H. Guss,\\nA. Nichol, A. Paino, N. Tezak, J. Tang, I. Babuschkin, S. Balaji, S. Jain, W. Saunders, C. Hesse,\\nA. N. Carr, J. Leike, J. Achiam, V . Misra, E. Morikawa, A. Radford, M. Knight, M. Brundage,\\nM. Murati, K. Mayer, P . Welinder, B. McGrew, D. Amodei, S. McCandlish, I. Sutskever, and\\nW. Zaremba. Evaluating large language models trained on code. CoRR, abs/2107.03374, 2021.\\nURL https://arxiv.org/abs/2107.03374.\\nA. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. Al-Dahle, A. Letman, A. Mathur, A. Schelten,\\nA. Yang, A. Fan, et al. The llama 3 herd of models. arXiv preprint arXiv:2407.21783, 2024.\\nY. Dubois, B. Galambosi, P . Liang, and T. B. Hashimoto. Length-controlled alpacaeval: A simple\\nway to debias automatic evaluators. arXiv preprint arXiv:2404.04475, 2024.\\nX. Feng, Z. Wan, M. Wen, S. M. McAleer, Y. Wen, W. Zhang, and J. Wang. Alphazero-like\\ntree-search can guide large language model decoding and training, 2024. URL https:\\n//arxiv.org/abs/2309.17179.\\nL. Gao, J. Schulman, and J. Hilton. Scaling laws for reward model overoptimization, 2022. URL\\nhttps://arxiv.org/abs/2210.10760.\\nA. P . Gema, J. O. J. Leang, G. Hong, A. Devoto, A. C. M. Mancino, R. Saxena, X. He, Y. Zhao,\\nX. Du, M. R. G. Madani, C. Barale, R. McHardy, J. Harris, J. Kaddour, E. van Krieken, and\\nP . Minervini. Are we done with mmlu? CoRR, abs/2406.04127, 2024. URL https://doi.or\\ng/10.48550/arXiv.2406.04127.\\nGoogle. Our next-generation model: Gemini 1.5, 2024. URL https://blog.google/techno\\nlogy/ai/google-gemini-next-generation-model-february-2024 .\\nY. He, S. Li, J. Liu, Y. Tan, W. Wang, H. Huang, X. Bu, H. Guo, C. Hu, B. Zheng, et al. Chi-\\nnese simpleqa: A chinese factuality evaluation for large language models. arXiv preprint\\narXiv:2411.07140, 2024.\\nD. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. Measuring\\nmassive multitask language understanding. arXiv preprint arXiv:2009.03300, 2020.\\nY. Huang, Y. Bai, Z. Zhu, J. Zhang, J. Zhang, T. Su, J. Liu, C. Lv, Y. Zhang, J. Lei, et al. C-Eval: A\\nmulti-level multi-discipline chinese evaluation suite for foundation models. arXiv preprint\\narXiv:2305.08322, 2023.\\nN. Jain, K. Han, A. Gu, W. Li, F. Yan, T. Zhang, S. Wang, A. Solar-Lezama, K. Sen, and I. Stoica.\\nLivecodebench: Holistic and contamination free evaluation of large language models for code.\\nCoRR, abs/2403.07974, 2024. URL https://doi.org/10.48550/arXiv.2403.07974.\\n17', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='201097dd-9e96-4b2c-aeae-5d38eca449b2', embedding=None, metadata={'page_label': '18', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='S. Krishna, K. Krishna, A. Mohananey, S. Schwarcz, A. Stambler, S. Upadhyay, and M. Faruqui.\\nFact, fetch, and reason: A unified evaluation of retrieval-augmented generation. CoRR,\\nabs/2409.12941, 2024. doi: 10.48550/ARXIV.2409.12941. URL https://doi.org/10.485\\n50/arXiv.2409.12941.\\nA. Kumar, V . Zhuang, R. Agarwal, Y. Su, J. D. Co-Reyes, A. Singh, K. Baumli, S. Iqbal, C. Bishop,\\nR. Roelofs, et al. Training language models to self-correct via reinforcement learning. arXiv\\npreprint arXiv:2409.12917, 2024.\\nH. Li, Y. Zhang, F. Koto, Y. Yang, H. Zhao, Y. Gong, N. Duan, and T. Baldwin. CMMLU: Measur-\\ning massive multitask language understanding in Chinese. arXiv preprint arXiv:2306.09212,\\n2023.\\nT. Li, W.-L. Chiang, E. Frick, L. Dunlap, T. Wu, B. Zhu, J. E. Gonzalez, and I. Stoica. From\\ncrowdsourced data to high-quality benchmarks: Arena-hard and benchbuilder pipeline. arXiv\\npreprint arXiv:2406.11939, 2024.\\nH. Lightman, V . Kosaraju, Y. Burda, H. Edwards, B. Baker, T. Lee, J. Leike, J. Schulman,\\nI. Sutskever, and K. Cobbe. Let’s verify step by step. arXiv preprint arXiv:2305.20050, 2023.\\nB. Y. Lin. ZeroEval: A Unified Framework for Evaluating Language Models, July 2024. URL\\nhttps://github.com/WildEval/ZeroEval.\\nMAA. American invitational mathematics examination - aime. In American Invitational\\nMathematics Examination - AIME 2024, February 2024. URL https://maa.org/math\\n-competitions/american-invitational-mathematics-examination-aime .\\nOpenAI. Hello GPT-4o, 2024a. URL https://openai.com/index/hello-gpt-4o/.\\nOpenAI. Learning to reason with llms, 2024b. URL https://openai.com/index/learnin\\ng-to-reason-with-llms/ .\\nOpenAI. Introducing SimpleQA, 2024c. URL https://openai.com/index/introducing\\n-simpleqa/.\\nOpenAI. Introducing SWE-bench verified we’re releasing a human-validated subset of swe-\\nbench that more, 2024d. URL https://openai.com/index/introducing-swe-bench\\n-verified/.\\nQwen. Qwq: Reflect deeply on the boundaries of the unknown, 2024a. URL https://qwenlm\\n.github.io/blog/qwq-32b-preview/.\\nQwen. Qwen2.5: A party of foundation models, 2024b. URL https://qwenlm.github.io/b\\nlog/qwen2.5.\\nD. Rein, B. L. Hou, A. C. Stickland, J. Petty, R. Y. Pang, J. Dirani, J. Michael, and S. R. Bowman.\\nGPQA: A graduate-level google-proof q&a benchmark. arXiv preprint arXiv:2311.12022, 2023.\\nZ. Shao, P . Wang, Q. Zhu, R. Xu, J. Song, M. Zhang, Y. Li, Y. Wu, and D. Guo. Deepseekmath:\\nPushing the limits of mathematical reasoning in open language models. arXiv preprint\\narXiv:2402.03300, 2024.\\nD. Silver, T. Hubert, J. Schrittwieser, I. Antonoglou, M. Lai, A. Guez, M. Lanctot, L. Sifre,\\nD. Kumaran, T. Graepel, T. P . Lillicrap, K. Simonyan, and D. Hassabis. Mastering chess and\\nshogi by self-play with a general reinforcement learning algorithm. CoRR, abs/1712.01815,\\n2017a. URL http://arxiv.org/abs/1712.01815.\\n18', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='cc3e81db-3522-4bb0-996a-ae89ea5d86d3', embedding=None, metadata={'page_label': '19', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker,\\nM. Lai, A. Bolton, Y. Chen, T. P . Lillicrap, F. Hui, L. Sifre, G. van den Driessche, T. Graepel, and\\nD. Hassabis. Mastering the game of go without human knowledge. Nat., 550(7676):354–359,\\n2017b. doi: 10.1038/NATURE24270. URL https://doi.org/10.1038/nature24270.\\nC. Snell, J. Lee, K. Xu, and A. Kumar. Scaling llm test-time compute optimally can be more\\neffective than scaling model parameters, 2024. URL https://arxiv.org/abs/2408.033\\n14.\\nT. Trinh, Y. Wu, Q. Le, H. He, and T. Luong. Solving olympiad geometry without human\\ndemonstrations. Nature, 2024. doi: 10.1038/s41586-023-06747-5.\\nJ. Uesato, N. Kushman, R. Kumar, F. Song, N. Siegel, L. Wang, A. Creswell, G. Irving, and\\nI. Higgins. Solving math word problems with process-and outcome-based feedback. arXiv\\npreprint arXiv:2211.14275, 2022.\\nP . Wang, L. Li, Z. Shao, R. Xu, D. Dai, Y. Li, D. Chen, Y. Wu, and Z. Sui. Math-shepherd: A label-\\nfree step-by-step verifier for llms in mathematical reasoning. arXiv preprint arXiv:2312.08935,\\n2023.\\nX. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, S. Narang, A. Chowdhery, and D. Zhou.\\nSelf-consistency improves chain of thought reasoning in language models. arXiv preprint\\narXiv:2203.11171, 2022.\\nY. Wang, X. Ma, G. Zhang, Y. Ni, A. Chandra, S. Guo, W. Ren, A. Arulraj, X. He, Z. Jiang, T. Li,\\nM. Ku, K. Wang, A. Zhuang, R. Fan, X. Yue, and W. Chen. Mmlu-pro: A more robust and\\nchallenging multi-task language understanding benchmark. CoRR, abs/2406.01574, 2024.\\nURL https://doi.org/10.48550/arXiv.2406.01574.\\nC. S. Xia, Y. Deng, S. Dunn, and L. Zhang. Agentless: Demystifying llm-based software\\nengineering agents. arXiv preprint, 2024.\\nH. Xin, Z. Z. Ren, J. Song, Z. Shao, W. Zhao, H. Wang, B. Liu, L. Zhang, X. Lu, Q. Du, W. Gao,\\nQ. Zhu, D. Yang, Z. Gou, Z. F. Wu, F. Luo, and C. Ruan. Deepseek-prover-v1.5: Harnessing\\nproof assistant feedback for reinforcement learning and monte-carlo tree search, 2024. URL\\nhttps://arxiv.org/abs/2408.08152.\\nJ. Zhou, T. Lu, S. Mishra, S. Brahma, S. Basu, Y. Luan, D. Zhou, and L. Hou. Instruction-following\\nevaluation for large language models. arXiv preprint arXiv:2311.07911, 2023.\\n19', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='22b3c2a2-57c7-480c-bcd1-02d3a35bdd05', embedding=None, metadata={'page_label': '20', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Appendix\\nA. Contributions and Acknowledgments\\nCore Contributors\\nDaya Guo\\nDejian Yang\\nHaowei Zhang\\nJunxiao Song\\nRuoyu Zhang\\nRunxin Xu\\nQihao Zhu\\nShirong Ma\\nPeiyi Wang\\nXiao Bi\\nXiaokang Zhang\\nXingkai Yu\\nYu Wu\\nZ.F. Wu\\nZhibin Gou\\nZhihong Shao\\nZhuoshu Li\\nZiyi Gao\\nContributors\\nAixin Liu\\nBing Xue\\nBingxuan Wang\\nBochao Wu\\nBei Feng\\nChengda Lu\\nChenggang Zhao\\nChengqi Deng\\nChong Ruan\\nDamai Dai\\nDeli Chen\\nDongjie Ji\\nErhang Li\\nFangyun Lin\\nFucong Dai\\nFuli Luo*\\nGuangbo Hao\\nGuanting Chen\\nGuowei Li\\nH. Zhang\\nHanwei Xu\\nHonghui Ding\\nHuazuo Gao\\nHui Qu\\nHui Li\\nJianzhong Guo\\nJiashi Li\\nJingchang Chen\\nJingyang Yuan\\nJinhao Tu\\nJunjie Qiu\\nJunlong Li\\nJ.L. Cai\\nJiaqi Ni\\nJian Liang\\nJin Chen\\nKai Dong\\nKai Hu*\\nKaichao You\\nKaige Gao\\nKang Guan\\nKexin Huang\\nKuai Yu\\nLean Wang\\nLecong Zhang\\nLiang Zhao\\nLitong Wang\\nLiyue Zhang\\nLei Xu\\nLeyi Xia\\nMingchuan Zhang\\nMinghua Zhang\\nMinghui Tang\\nMingxu Zhou\\nMeng Li\\nMiaojun Wang\\nMingming Li\\nNing Tian\\nPanpan Huang\\nPeng Zhang\\nQiancheng Wang\\nQinyu Chen\\nQiushi Du\\nRuiqi Ge*\\nRuisong Zhang\\nRuizhe Pan\\nRunji Wang\\nR.J. Chen\\nR.L. Jin\\n20', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='3fce3f43-9848-4b66-a47b-5b2d1d51d27c', embedding=None, metadata={'page_label': '21', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Ruyi Chen\\nShanghao Lu\\nShangyan Zhou\\nShanhuang Chen\\nShengfeng Ye\\nShiyu Wang\\nShuiping Yu\\nShunfeng Zhou\\nShuting Pan\\nS.S. Li\\nShuang Zhou\\nShaoqing Wu\\nShengfeng Ye\\nTao Yun\\nTian Pei\\nTianyu Sun\\nT. Wang\\nWangding Zeng\\nWen Liu\\nWenfeng Liang\\nWenjun Gao\\nWenqin Yu*\\nWentao Zhang\\nW.L. Xiao\\nWei An\\nXiaodong Liu\\nXiaohan Wang\\nXiaokang Chen\\nXiaotao Nie\\nXin Cheng\\nXin Liu\\nXin Xie\\nXingchao Liu\\nXinyu Yang\\nXinyuan Li\\nXuecheng Su\\nXuheng Lin\\nX.Q. Li\\nXiangyue Jin\\nXiaojin Shen\\nXiaosha Chen\\nXiaowen Sun\\nXiaoxiang Wang\\nXinnan Song\\nXinyi Zhou\\nXianzu Wang\\nXinxia Shan\\nY.K. Li\\nY.Q. Wang\\nY.X. Wei\\nYang Zhang\\nYanhong Xu\\nYao Li\\nYao Zhao\\nYaofeng Sun\\nYaohui Wang\\nYi Yu\\nYichao Zhang\\nYifan Shi\\nYiliang Xiong\\nYing He\\nYishi Piao\\nYisong Wang\\nYixuan Tan\\nYiyang Ma*\\nYiyuan Liu\\nYongqiang Guo\\nYuan Ou\\nYuduan Wang\\nYue Gong\\nYuheng Zou\\nYujia He\\nYunfan Xiong\\nYuxiang Luo\\nYuxiang You\\nYuxuan Liu\\nYuyang Zhou\\nY.X. Zhu\\nYanping Huang\\nYaohui Li\\nYi Zheng\\nYuchen Zhu\\nYunxian Ma\\nYing Tang\\nYukun Zha\\nYuting Yan\\nZ.Z. Ren\\nZehui Ren\\nZhangli Sha\\nZhe Fu\\nZhean Xu\\nZhenda Xie\\nZhengyan Zhang\\nZhewen Hao\\nZhicheng Ma\\nZhigang Yan\\nZhiyu Wu\\nZihui Gu\\n21', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='52adddfe-a038-41fc-b3a0-e1fea8a2b1ce', embedding=None, metadata={'page_label': '22', 'file_name': 'DeepSeek_R1.pdf', 'file_path': '/Users/arihantsingla/Documents/RAG_Application/notebook/DATA/DeepSeek_R1.pdf', 'file_type': 'application/pdf', 'file_size': 1328991, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Zijia Zhu\\nZijun Liu*\\nZilin Li\\nZiwei Xie\\nZiyang Song\\nZizheng Pan\\nZhen Huang\\nZhipeng Xu\\nZhongyu Zhang\\nZhen Zhang\\nWithin each role, authors are listed alphabetically by the first name. Names marked with *\\ndenote individuals who have departed from our team.\\n22', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "system_prompt = \"You are a helpful assistant that can answer questions with appropriate context from the given documents\"\n",
    "\n",
    "llm = HuggingFaceLLM(\n",
    "    context_window=4096,\n",
    "    max_new_tokens=256,\n",
    "    generate_kwargs={\"temperature\": 0.7, \"top_p\": 0.9, \"top_k\": 50,\"do_sample\": False},\n",
    "    tokenizer=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "    device_map=\"auto\",\n",
    "    query_wrapper_prompt=query_prompt,\n",
    "    system_prompt=system_prompt,\n",
    "    # model_kwargs={\"torch_dtype\": torch.float16,\"load_in_8bit\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
